{
  
    
        "post0": {
            "title": "Implementing Naive Bayes Classifier using Python",
            "content": "About . Explore how to implement the Naive Bayes Classifier in Python using a dataset from the UCI Machine Learning Repository. . Dataset info . &quot;The target attribute for classification is Category (blood donors vs. Hepatitis C (including its progress (&#39;just&#39; Hepatitis C, Fibrosis, Cirrhosis)&quot; . DataSet Source: . Creators: Ralf Lichtinghagen, Frank Klawonn, Georg Hoffmann . Donor: Ralf Lichtinghagen: Institute of Clinical Chemistry; Medical University Hannover (MHH); Hannover, Germany; lichtinghagen.ralf &#39;@&#39; mh-hannover.de . Donor: Frank Klawonn; Helmholtz Centre for Infection Research; Braunschweig, Germany; frank.klawonn &#39;@&#39; helmholtz-hzi.de . Donor: Georg Hoffmann; Trillium GmbH; Grafrath, Germany; georg.hoffmann &#39;@&#39; trillium.de . What is the Naive Bayes classifier . Naive Bayes classifier is considered to be a family of supervised learning algorithms known as &#39;probablistic classifiers&#39; that is based on applying the Bayes&#39; theorem, and also assumes strong feature independence. . Why and When to use Naive Bayes classifier . Naive Bayes is actually simple to use and relatively fast when compared to other classification algorithms. . These classifier have worked well in applications such as multiclass prediction, text classification and spam filtering. In the Scikit Learn library, there are a few Naive Bayes algorithms: . Gaussian Naive Bayes: Assumes the features have a gaussian distribution. . | Multinomial Naive Bayes: Assumes multinominally distributed data, and typically used for text classification. . | Complement Naive Bayes: Is an adaptation of the standard multinomial Naive Bayes algorithm, and regularly outperforms on text classification task. . | Bernoulli Naive Bayes: Assumes the features are binary-valued variables. . | Categorical Naive Bayes: Assumes each feature has its own categorical distribution. . | Import Libraries and load dataset . import matplotlib.pyplot as plt %matplotlib inline import pandas as pd import seaborn as sns import numpy as np from google.colab import files . uploaded = files.upload() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving hcvdat0.csv to hcvdat0 (1).csv . import io hcv = pd.read_csv(io.BytesIO(uploaded[&#39;hcvdat0.csv&#39;])) ##used BytesIO instead of StringIO hcv . Unnamed: 0 Category Age Sex ALB ALP ALT AST BIL CHE CHOL CREA GGT PROT . 0 1 | 0=Blood Donor | 32 | m | 38.5 | 52.5 | 7.7 | 22.1 | 7.5 | 6.93 | 3.23 | 106.0 | 12.1 | 69.0 | . 1 2 | 0=Blood Donor | 32 | m | 38.5 | 70.3 | 18.0 | 24.7 | 3.9 | 11.17 | 4.80 | 74.0 | 15.6 | 76.5 | . 2 3 | 0=Blood Donor | 32 | m | 46.9 | 74.7 | 36.2 | 52.6 | 6.1 | 8.84 | 5.20 | 86.0 | 33.2 | 79.3 | . 3 4 | 0=Blood Donor | 32 | m | 43.2 | 52.0 | 30.6 | 22.6 | 18.9 | 7.33 | 4.74 | 80.0 | 33.8 | 75.7 | . 4 5 | 0=Blood Donor | 32 | m | 39.2 | 74.1 | 32.6 | 24.8 | 9.6 | 9.15 | 4.32 | 76.0 | 29.9 | 68.7 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 610 611 | 3=Cirrhosis | 62 | f | 32.0 | 416.6 | 5.9 | 110.3 | 50.0 | 5.57 | 6.30 | 55.7 | 650.9 | 68.5 | . 611 612 | 3=Cirrhosis | 64 | f | 24.0 | 102.8 | 2.9 | 44.4 | 20.0 | 1.54 | 3.02 | 63.0 | 35.9 | 71.3 | . 612 613 | 3=Cirrhosis | 64 | f | 29.0 | 87.3 | 3.5 | 99.0 | 48.0 | 1.66 | 3.63 | 66.7 | 64.2 | 82.0 | . 613 614 | 3=Cirrhosis | 46 | f | 33.0 | NaN | 39.0 | 62.0 | 20.0 | 3.56 | 4.20 | 52.0 | 50.0 | 71.0 | . 614 615 | 3=Cirrhosis | 59 | f | 36.0 | NaN | 100.0 | 80.0 | 12.0 | 9.07 | 5.30 | 67.0 | 34.0 | 68.0 | . 615 rows × 14 columns . Inspect data . hcv.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 615 entries, 0 to 614 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 Unnamed: 0 615 non-null int64 1 Category 615 non-null object 2 Age 615 non-null int64 3 Sex 615 non-null object 4 ALB 614 non-null float64 5 ALP 597 non-null float64 6 ALT 614 non-null float64 7 AST 615 non-null float64 8 BIL 615 non-null float64 9 CHE 615 non-null float64 10 CHOL 605 non-null float64 11 CREA 615 non-null float64 12 GGT 615 non-null float64 13 PROT 614 non-null float64 dtypes: float64(10), int64(2), object(2) memory usage: 67.4+ KB . hcv[&#39;Category&#39;] = hcv[&#39;Category&#39;].astype(&#39;category&#39;) # change the objects to category type data hcv[&#39;Sex&#39;] = hcv[&quot;Sex&quot;].astype(&#39;category&#39;) . hcv[&#39;Category&#39;].unique() . [&#39;0=Blood Donor&#39;, &#39;0s=suspect Blood Donor&#39;, &#39;1=Hepatitis&#39;, &#39;2=Fibrosis&#39;, &#39;3=Cirrhosis&#39;] Categories (5, object): [&#39;0=Blood Donor&#39;, &#39;0s=suspect Blood Donor&#39;, &#39;1=Hepatitis&#39;, &#39;2=Fibrosis&#39;, &#39;3=Cirrhosis&#39;] . sns.countplot(y=&#39;Category&#39;, data = hcv) plt.show() . sns.countplot(y=&#39;Sex&#39;, data=hcv) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9bd7225940&gt; . suspect = hcv.loc[hcv[&#39;Category&#39;] == &#39;0s=suspect Blood Donor&#39;] # check the values for Os = suspect blood donor suspect . Unnamed: 0 Category Age Sex ALB ALP ALT AST BIL CHE CHOL CREA GGT PROT . 533 534 | 0s=suspect Blood Donor | 47 | m | 22.5 | 124.0 | 79.5 | 46.7 | 2.3 | 6.83 | 4.30 | 170.0 | 345.6 | 58.6 | . 534 535 | 0s=suspect Blood Donor | 48 | m | 24.9 | 116.9 | 49.2 | 24.3 | 4.9 | 3.44 | 5.25 | 29.0 | 83.0 | 47.8 | . 535 536 | 0s=suspect Blood Donor | 49 | m | 21.6 | 42.2 | 9.5 | 10.6 | 2.4 | 3.75 | 3.01 | 64.0 | 38.9 | 44.8 | . 536 537 | 0s=suspect Blood Donor | 55 | m | 47.3 | 106.0 | 208.8 | 130.6 | 0.8 | 14.80 | 8.08 | 76.0 | 71.6 | 78.3 | . 537 538 | 0s=suspect Blood Donor | 71 | m | 14.9 | 69.8 | 19.7 | 95.2 | 9.8 | 13.30 | 2.61 | 9.0 | 7.6 | 47.0 | . 538 539 | 0s=suspect Blood Donor | 74 | m | 20.3 | 84.0 | 22.8 | 43.0 | 5.7 | 4.91 | 3.19 | 52.0 | 218.3 | 47.8 | . 539 540 | 0s=suspect Blood Donor | 59 | f | 19.3 | 208.2 | 325.3 | 146.6 | 6.9 | 5.33 | 4.72 | 32.0 | 295.6 | 53.1 | . hcv[hcv[&#39;ALP&#39;].isnull()] . Unnamed: 0 Category Age Sex ALB ALP ALT AST BIL CHE CHOL CREA GGT PROT . 541 542 | 1=Hepatitis | 19 | m | 41.0 | NaN | 87.0 | 67.0 | 12.0 | 7.55 | 3.9 | 62.0 | 65.0 | 75.0 | . 545 546 | 1=Hepatitis | 29 | m | 49.0 | NaN | 53.0 | 39.0 | 15.0 | 8.79 | 3.6 | 79.0 | 37.0 | 90.0 | . 546 547 | 1=Hepatitis | 30 | m | 45.0 | NaN | 66.0 | 45.0 | 14.0 | 12.16 | 6.1 | 86.0 | 43.0 | 77.0 | . 568 569 | 2=Fibrosis | 49 | m | 39.0 | NaN | 118.0 | 62.0 | 10.0 | 7.28 | 3.5 | 72.0 | 74.0 | 81.0 | . 569 570 | 2=Fibrosis | 49 | m | 46.0 | NaN | 114.0 | 75.0 | 16.0 | 10.43 | 5.2 | 72.0 | 59.0 | 82.0 | . 570 571 | 2=Fibrosis | 50 | m | 42.0 | NaN | 258.0 | 106.0 | 15.0 | 8.74 | 4.7 | 77.0 | 80.0 | 84.0 | . 571 572 | 2=Fibrosis | 53 | m | 46.0 | NaN | 34.0 | 43.0 | 14.0 | 8.77 | 4.0 | 112.0 | 203.0 | 76.0 | . 576 577 | 2=Fibrosis | 71 | m | 37.0 | NaN | 130.0 | 90.0 | 15.0 | 9.92 | 4.7 | 79.0 | 77.0 | 76.0 | . 581 582 | 2=Fibrosis | 49 | f | 39.0 | NaN | 46.0 | 39.0 | 9.0 | 10.21 | 3.1 | 89.0 | 53.0 | 79.0 | . 582 583 | 2=Fibrosis | 51 | f | 37.0 | NaN | 164.0 | 70.0 | 9.0 | 3.99 | 4.2 | 67.0 | 43.0 | 72.0 | . 583 584 | 2=Fibrosis | 56 | f | 39.0 | NaN | 42.0 | 34.0 | 10.0 | 7.75 | 5.0 | 80.0 | 84.0 | 78.0 | . 584 585 | 2=Fibrosis | 75 | f | 36.0 | NaN | 114.0 | 125.0 | 14.0 | 6.65 | NaN | 57.0 | 177.0 | 72.0 | . 585 586 | 3=Cirrhosis | 38 | m | 44.0 | NaN | 94.0 | 60.0 | 12.0 | 4.37 | 3.2 | 61.0 | 99.0 | 77.0 | . 590 591 | 3=Cirrhosis | 46 | m | 20.0 | NaN | 62.0 | 113.0 | 254.0 | 1.48 | NaN | 114.0 | 138.0 | NaN | . 592 593 | 3=Cirrhosis | 47 | m | 42.0 | NaN | 159.0 | 102.0 | 11.0 | 6.29 | 5.5 | 58.0 | 201.0 | 79.0 | . 603 604 | 3=Cirrhosis | 65 | m | NaN | NaN | 40.0 | 54.0 | 13.0 | 7.50 | NaN | 70.0 | 107.0 | 79.0 | . 613 614 | 3=Cirrhosis | 46 | f | 33.0 | NaN | 39.0 | 62.0 | 20.0 | 3.56 | 4.2 | 52.0 | 50.0 | 71.0 | . 614 615 | 3=Cirrhosis | 59 | f | 36.0 | NaN | 100.0 | 80.0 | 12.0 | 9.07 | 5.3 | 67.0 | 34.0 | 68.0 | . Perform Encoding for Categorical variables . from sklearn.preprocessing import LabelEncoder # use label encoder for male vs female label = LabelEncoder() #initialize hcv[&#39;Gender&#39;] = label.fit_transform(hcv[&#39;Sex&#39;]) hcv . Unnamed: 0 Category Age Sex ALB ALP ALT AST BIL CHE CHOL CREA GGT PROT Gender . 0 1 | 0=Blood Donor | 32 | m | 38.5 | 52.5 | 7.7 | 22.1 | 7.5 | 6.93 | 3.23 | 106.0 | 12.1 | 69.0 | 1 | . 1 2 | 0=Blood Donor | 32 | m | 38.5 | 70.3 | 18.0 | 24.7 | 3.9 | 11.17 | 4.80 | 74.0 | 15.6 | 76.5 | 1 | . 2 3 | 0=Blood Donor | 32 | m | 46.9 | 74.7 | 36.2 | 52.6 | 6.1 | 8.84 | 5.20 | 86.0 | 33.2 | 79.3 | 1 | . 3 4 | 0=Blood Donor | 32 | m | 43.2 | 52.0 | 30.6 | 22.6 | 18.9 | 7.33 | 4.74 | 80.0 | 33.8 | 75.7 | 1 | . 4 5 | 0=Blood Donor | 32 | m | 39.2 | 74.1 | 32.6 | 24.8 | 9.6 | 9.15 | 4.32 | 76.0 | 29.9 | 68.7 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 610 611 | 3=Cirrhosis | 62 | f | 32.0 | 416.6 | 5.9 | 110.3 | 50.0 | 5.57 | 6.30 | 55.7 | 650.9 | 68.5 | 0 | . 611 612 | 3=Cirrhosis | 64 | f | 24.0 | 102.8 | 2.9 | 44.4 | 20.0 | 1.54 | 3.02 | 63.0 | 35.9 | 71.3 | 0 | . 612 613 | 3=Cirrhosis | 64 | f | 29.0 | 87.3 | 3.5 | 99.0 | 48.0 | 1.66 | 3.63 | 66.7 | 64.2 | 82.0 | 0 | . 613 614 | 3=Cirrhosis | 46 | f | 33.0 | NaN | 39.0 | 62.0 | 20.0 | 3.56 | 4.20 | 52.0 | 50.0 | 71.0 | 0 | . 614 615 | 3=Cirrhosis | 59 | f | 36.0 | NaN | 100.0 | 80.0 | 12.0 | 9.07 | 5.30 | 67.0 | 34.0 | 68.0 | 0 | . 615 rows × 15 columns . drop_index = hcv.loc[hcv[&#39;Category&#39;] == &#39;0s=suspect Blood Donor&#39;].index # Drop rows with Os=suspect blood donor hcv.drop(drop_index, inplace=True) . hcv_dict = {&#39;0=Blood Donor&#39;: 0, &#39;1=Hepatitis&#39; : 1, &#39;2=Fibrosis&#39; : 2, &#39;3=Cirrhosis&#39;: 3} hcv[&quot;New Category&quot;] = hcv[&#39;Category&#39;].map(hcv_dict).astype(&#39;int32&#39;) # create new column for Category to remap values hcv . Unnamed: 0 Category Age Sex ALB ALP ALT AST BIL CHE CHOL CREA GGT PROT Gender New Category . 0 1 | 0=Blood Donor | 32 | m | 38.5 | 52.5 | 7.7 | 22.1 | 7.5 | 6.93 | 3.23 | 106.0 | 12.1 | 69.0 | 1 | 0 | . 1 2 | 0=Blood Donor | 32 | m | 38.5 | 70.3 | 18.0 | 24.7 | 3.9 | 11.17 | 4.80 | 74.0 | 15.6 | 76.5 | 1 | 0 | . 2 3 | 0=Blood Donor | 32 | m | 46.9 | 74.7 | 36.2 | 52.6 | 6.1 | 8.84 | 5.20 | 86.0 | 33.2 | 79.3 | 1 | 0 | . 3 4 | 0=Blood Donor | 32 | m | 43.2 | 52.0 | 30.6 | 22.6 | 18.9 | 7.33 | 4.74 | 80.0 | 33.8 | 75.7 | 1 | 0 | . 4 5 | 0=Blood Donor | 32 | m | 39.2 | 74.1 | 32.6 | 24.8 | 9.6 | 9.15 | 4.32 | 76.0 | 29.9 | 68.7 | 1 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 610 611 | 3=Cirrhosis | 62 | f | 32.0 | 416.6 | 5.9 | 110.3 | 50.0 | 5.57 | 6.30 | 55.7 | 650.9 | 68.5 | 0 | 3 | . 611 612 | 3=Cirrhosis | 64 | f | 24.0 | 102.8 | 2.9 | 44.4 | 20.0 | 1.54 | 3.02 | 63.0 | 35.9 | 71.3 | 0 | 3 | . 612 613 | 3=Cirrhosis | 64 | f | 29.0 | 87.3 | 3.5 | 99.0 | 48.0 | 1.66 | 3.63 | 66.7 | 64.2 | 82.0 | 0 | 3 | . 613 614 | 3=Cirrhosis | 46 | f | 33.0 | NaN | 39.0 | 62.0 | 20.0 | 3.56 | 4.20 | 52.0 | 50.0 | 71.0 | 0 | 3 | . 614 615 | 3=Cirrhosis | 59 | f | 36.0 | NaN | 100.0 | 80.0 | 12.0 | 9.07 | 5.30 | 67.0 | 34.0 | 68.0 | 0 | 3 | . 608 rows × 16 columns . Transform Data . hcv.dropna(how=&#39;any&#39;, inplace=True) # drop rows with null values ## split into features and label/target X = hcv.iloc[:, 2:-1].drop(columns = &#39;Sex&#39;).to_numpy() # features y = hcv.iloc[:, -1].to_numpy() # label/target . Create test train split . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) . Generate Model using Naive Bayes Classifier - GaussianNB . from sklearn.naive_bayes import GaussianNB #Import Gaussian Naive Bayes model clf = GaussianNB() #Inititate Gaussian Classifier clf.fit(X_train,y_train) # Train the model using the training sets y_pred = clf.predict(X_test) # perform prediction . Evaluate Model . from sklearn.metrics import accuracy_score accuracy_score(y_test, y_pred) . 0.9222797927461139 . Generate and Evaluate Model using Naive Bayes Classifier - Multinomial . from sklearn.naive_bayes import MultinomialNB #Import Multinomial Naive Bayes model clf = MultinomialNB() #Inititate Multinomial Classifier clf.fit(X_train,y_train) # Train the model using the training sets y_pred = clf.predict(X_test) # perform prediction from sklearn.metrics import accuracy_score accuracy_score(y_test, y_pred) . 0.9015544041450777 . References . UCI Machine Learning Repository - HCV dataset. Accessed 15-Nov-2020. . Sklearn Naive_Bayes. Accessed 15-Nov-2020. . Sklearn Metrics - accuracy_score. Accessed 15-Nov-2020. . Sklearn test_train_split.Accessed 15-Nov-2020. . Naive_Bayes_Classifier. Accessed 15-Nov-2020. .",
            "url": "https://ijeomaodoko.github.io/my-blog/python/supervised_machine_learning/probablistic_classifiers/naive_bayes/2020/11/16/Naive_Bayes_Classifier.html",
            "relUrl": "/python/supervised_machine_learning/probablistic_classifiers/naive_bayes/2020/11/16/Naive_Bayes_Classifier.html",
            "date": " • Nov 16, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Sentiment Analysis using vaderSentiment Python Library",
            "content": "About . Sentiment Analysis is a field of natural language processing that seeks to use machine learning techniques to determine sentiment scores for a body of text. The idea is to determine the polarity of the phrase or sentence as negative, neutral or positive. In some cases to determine if a statement is objective or subjective. . Our dataset is from the Kaggle website, &quot;it contains 1.6 million tweets extracted using the twitter api&quot;. Since this a very large dataset, we will be using pandas_profiling for quick data analysis. We also expect longer runtimes for some of the codes. . The polarity of the tweets are annotated as 0 = negative and 4 = positive. . To perform the sentiment analysis, the vaderSentiment library will be used. It was created specifically for analyzing sentiments expressed in seocial media. VADER stands for Valence Aware Dictionary and Sentiment Reasoner. . However with the vaderSentiment however we are going to reclassify polarity as negative, neutral and negative sentiment. Typical thresholds from the vaderSentiment GitHub Page as follows: . Sentiment Compound . Positive | &gt;= 0.05 | . Neutral | &gt; -0.05 and &lt; 0.05 | . Negative | &lt;= -0.05 | . | | . Install required dependencies . !pip install vaderSentiment . Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.3.2) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;vaderSentiment) (2020.6.20) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;vaderSentiment) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;vaderSentiment) (1.24.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;vaderSentiment) (2.10) . import sys !{sys.executable} -m pip install -U pandas-profiling[notebook] !jupyter nbextension enable --py widgetsnbextension . Requirement already up-to-date: pandas-profiling[notebook] in /usr/local/lib/python3.6/dist-packages (2.9.0) Requirement already satisfied, skipping upgrade: matplotlib&gt;=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (3.2.2) Requirement already satisfied, skipping upgrade: tangled-up-in-unicode&gt;=0.0.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.0.6) Requirement already satisfied, skipping upgrade: requests&gt;=2.23.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (2.23.0) Requirement already satisfied, skipping upgrade: seaborn&gt;=0.10.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.11.0) Requirement already satisfied, skipping upgrade: attrs&gt;=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (20.2.0) Requirement already satisfied, skipping upgrade: htmlmin&gt;=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.1.12) Requirement already satisfied, skipping upgrade: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,&gt;=0.25.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (1.1.3) Requirement already satisfied, skipping upgrade: missingno&gt;=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.4.2) Requirement already satisfied, skipping upgrade: jinja2&gt;=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (2.11.2) Requirement already satisfied, skipping upgrade: visions[type_image_path]==0.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.5.0) Requirement already satisfied, skipping upgrade: numpy&gt;=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (1.18.5) Requirement already satisfied, skipping upgrade: phik&gt;=0.9.10 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.10.0) Requirement already satisfied, skipping upgrade: tqdm&gt;=4.43.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (4.51.0) Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (0.17.0) Requirement already satisfied, skipping upgrade: ipywidgets&gt;=7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (7.5.1) Requirement already satisfied, skipping upgrade: scipy&gt;=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (1.4.1) Requirement already satisfied, skipping upgrade: confuse&gt;=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (1.3.0) Requirement already satisfied, skipping upgrade: jupyter-core&gt;=4.6.3; extra == &#34;notebook&#34; in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (4.6.3) Requirement already satisfied, skipping upgrade: jupyter-client&gt;=6.0.0; extra == &#34;notebook&#34; in /usr/local/lib/python3.6/dist-packages (from pandas-profiling[notebook]) (6.1.7) Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas-profiling[notebook]) (2.4.7) Requirement already satisfied, skipping upgrade: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas-profiling[notebook]) (1.2.0) Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas-profiling[notebook]) (2.8.1) Requirement already satisfied, skipping upgrade: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas-profiling[notebook]) (0.10.0) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.23.0-&gt;pandas-profiling[notebook]) (2.10) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.23.0-&gt;pandas-profiling[notebook]) (1.24.3) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.23.0-&gt;pandas-profiling[notebook]) (2020.6.20) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.23.0-&gt;pandas-profiling[notebook]) (3.0.4) Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,&gt;=0.25.3-&gt;pandas-profiling[notebook]) (2018.9) Requirement already satisfied, skipping upgrade: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2&gt;=2.11.1-&gt;pandas-profiling[notebook]) (1.1.1) Requirement already satisfied, skipping upgrade: networkx&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0-&gt;pandas-profiling[notebook]) (2.5) Requirement already satisfied, skipping upgrade: imagehash; extra == &#34;type_image_path&#34; in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0-&gt;pandas-profiling[notebook]) (4.1.0) Requirement already satisfied, skipping upgrade: Pillow; extra == &#34;type_image_path&#34; in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.5.0-&gt;pandas-profiling[notebook]) (7.0.0) Requirement already satisfied, skipping upgrade: numba&gt;=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik&gt;=0.9.10-&gt;pandas-profiling[notebook]) (0.48.0) Requirement already satisfied, skipping upgrade: nbformat&gt;=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (5.0.8) Requirement already satisfied, skipping upgrade: ipykernel&gt;=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (4.10.1) Requirement already satisfied, skipping upgrade: ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34; in /usr/local/lib/python3.6/dist-packages (from ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (5.5.0) Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (3.5.1) Requirement already satisfied, skipping upgrade: traitlets&gt;=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (4.3.3) Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse&gt;=1.0.0-&gt;pandas-profiling[notebook]) (3.13) Requirement already satisfied, skipping upgrade: tornado&gt;=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client&gt;=6.0.0; extra == &#34;notebook&#34;-&gt;pandas-profiling[notebook]) (5.1.1) Requirement already satisfied, skipping upgrade: pyzmq&gt;=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client&gt;=6.0.0; extra == &#34;notebook&#34;-&gt;pandas-profiling[notebook]) (19.0.2) Requirement already satisfied, skipping upgrade: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib&gt;=3.2.0-&gt;pandas-profiling[notebook]) (1.15.0) Requirement already satisfied, skipping upgrade: decorator&gt;=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx&gt;=2.4-&gt;visions[type_image_path]==0.5.0-&gt;pandas-profiling[notebook]) (4.4.2) Requirement already satisfied, skipping upgrade: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == &#34;type_image_path&#34;-&gt;visions[type_image_path]==0.5.0-&gt;pandas-profiling[notebook]) (1.1.1) Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba&gt;=0.38.1-&gt;phik&gt;=0.9.10-&gt;pandas-profiling[notebook]) (50.3.2) Requirement already satisfied, skipping upgrade: llvmlite&lt;0.32.0,&gt;=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba&gt;=0.38.1-&gt;phik&gt;=0.9.10-&gt;pandas-profiling[notebook]) (0.31.0) Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.2.0) Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,&gt;=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (2.6.0) Requirement already satisfied, skipping upgrade: prompt-toolkit&lt;2.0.0,&gt;=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (1.0.18) Requirement already satisfied, skipping upgrade: pexpect; sys_platform != &#34;win32&#34; in /usr/local/lib/python3.6/dist-packages (from ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (4.8.0) Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.7.5) Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (2.6.1) Requirement already satisfied, skipping upgrade: simplegeneric&gt;0.8 in /usr/local/lib/python3.6/dist-packages (from ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.8.1) Requirement already satisfied, skipping upgrade: notebook&gt;=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (5.3.1) Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit&lt;2.0.0,&gt;=1.0.4-&gt;ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.2.5) Requirement already satisfied, skipping upgrade: ptyprocess&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != &#34;win32&#34;-&gt;ipython&gt;=4.0.0; python_version &gt;= &#34;3.3&#34;-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.6.0) Requirement already satisfied, skipping upgrade: terminado&gt;=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.9.1) Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (1.5.0) Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (5.6.1) Requirement already satisfied, skipping upgrade: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.3) Requirement already satisfied, skipping upgrade: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (1.4.2) Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.4.4) Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.6.0) Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (3.2.1) Requirement already satisfied, skipping upgrade: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.8.4) Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (0.5.1) Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets&gt;=7.5.1-&gt;pandas-profiling[notebook]) (20.4) Enabling notebook extension jupyter-js-widgets/extension... - Validating: OK . Import required Libraries . import pandas as pd import numpy as np from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, classification_report from sklearn.discriminant_analysis import LinearDiscriminantAnalysis . Upload dataset and create dataframe . from google.colab import files files.upload() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving training.1600000.processed.noemoticon.csv to training.1600000.processed.noemoticon (1).csv . df = pd.read_csv(&#39;training.1600000.processed.noemoticon.csv&#39;, sep=&quot;,&quot; , header=None, encoding=&#39;latin-1&#39;, parse_dates=True, infer_datetime_format=True ) df . 0 1 2 3 4 5 . 0 0 | 1467810369 | Mon Apr 06 22:19:45 PDT 2009 | NO_QUERY | _TheSpecialOne_ | @switchfoot http://twitpic.com/2y1zl - Awww, t... | . 1 0 | 1467810672 | Mon Apr 06 22:19:49 PDT 2009 | NO_QUERY | scotthamilton | is upset that he can&#39;t update his Facebook by ... | . 2 0 | 1467810917 | Mon Apr 06 22:19:53 PDT 2009 | NO_QUERY | mattycus | @Kenichan I dived many times for the ball. Man... | . 3 0 | 1467811184 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | ElleCTF | my whole body feels itchy and like its on fire | . 4 0 | 1467811193 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | Karoli | @nationwideclass no, it&#39;s not behaving at all.... | . ... ... | ... | ... | ... | ... | ... | . 1599995 4 | 2193601966 | Tue Jun 16 08:40:49 PDT 2009 | NO_QUERY | AmandaMarie1028 | Just woke up. Having no school is the best fee... | . 1599996 4 | 2193601969 | Tue Jun 16 08:40:49 PDT 2009 | NO_QUERY | TheWDBoards | TheWDB.com - Very cool to hear old Walt interv... | . 1599997 4 | 2193601991 | Tue Jun 16 08:40:49 PDT 2009 | NO_QUERY | bpbabe | Are you ready for your MoJo Makeover? Ask me f... | . 1599998 4 | 2193602064 | Tue Jun 16 08:40:49 PDT 2009 | NO_QUERY | tinydiamondz | Happy 38th Birthday to my boo of alll time!!! ... | . 1599999 4 | 2193602129 | Tue Jun 16 08:40:50 PDT 2009 | NO_QUERY | RyanTrevMorris | happy #charitytuesday @theNSPCC @SparksCharity... | . 1600000 rows × 6 columns . df.columns = [&#39;Polarity&#39;, &#39;tweet_id&#39;, &#39;date&#39;, &#39;flag&#39;, &#39;user&#39;, &#39;text&#39;] df.head(5) . Polarity tweet_id date flag user text . 0 0 | 1467810369 | Mon Apr 06 22:19:45 PDT 2009 | NO_QUERY | _TheSpecialOne_ | @switchfoot http://twitpic.com/2y1zl - Awww, t... | . 1 0 | 1467810672 | Mon Apr 06 22:19:49 PDT 2009 | NO_QUERY | scotthamilton | is upset that he can&#39;t update his Facebook by ... | . 2 0 | 1467810917 | Mon Apr 06 22:19:53 PDT 2009 | NO_QUERY | mattycus | @Kenichan I dived many times for the ball. Man... | . 3 0 | 1467811184 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | ElleCTF | my whole body feels itchy and like its on fire | . 4 0 | 1467811193 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | Karoli | @nationwideclass no, it&#39;s not behaving at all.... | . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1600000 entries, 0 to 1599999 Data columns (total 6 columns): # Column Non-Null Count Dtype -- -- 0 Polarity 1600000 non-null int64 1 tweet_id 1600000 non-null int64 2 date 1600000 non-null object 3 flag 1600000 non-null object 4 user 1600000 non-null object 5 text 1600000 non-null object dtypes: int64(2), object(4) memory usage: 73.2+ MB . Perform Exploratory Data Analysis using Pandas_Profiling . This is a very large dataset with 1.6 million rows, we will use pandas_profiling to help us explore the data better and faster. . from pandas_profiling import ProfileReport # generate report profile = ProfileReport(df, title = &#39;Pandas Profiling Report&#39;, explorative=True) # to view it in Google Colab profile.to_notebook_iframe() . . df[&#39;text&#39;].astype(&#39;string&#39;, copy=True) # convert text from object to string . 0 @switchfoot http://twitpic.com/2y1zl - Awww, t... 1 is upset that he can&#39;t update his Facebook by ... 2 @Kenichan I dived many times for the ball. Man... 3 my whole body feels itchy and like its on fire 4 @nationwideclass no, it&#39;s not behaving at all.... ... 1599995 Just woke up. Having no school is the best fee... 1599996 TheWDB.com - Very cool to hear old Walt interv... 1599997 Are you ready for your MoJo Makeover? Ask me f... 1599998 Happy 38th Birthday to my boo of alll time!!! ... 1599999 happy #charitytuesday @theNSPCC @SparksCharity... Name: text, Length: 1600000, dtype: string . df[&#39;flag&#39;].unique() . array([&#39;NO_QUERY&#39;], dtype=object) . df[&#39;Polarity&#39;].unique() . array([0, 4]) . Apply Vader Sentiment Analysis function . sia = SentimentIntensityAnalyzer() sia_t = lambda x: sia.polarity_scores(x) # this function will return a dictionary of values df[&#39;pos&#39;,&#39;compound&#39;, &#39;neu&#39;, &#39;neg&#39; ] = df[&#39;text&#39;].apply(sia_t) print(df.head()) . Polarity ... (pos, compound, neu, neg) 0 0 ... {&#39;neg&#39;: 0.117, &#39;neu&#39;: 0.768, &#39;pos&#39;: 0.114, &#39;co... 1 0 ... {&#39;neg&#39;: 0.291, &#39;neu&#39;: 0.709, &#39;pos&#39;: 0.0, &#39;comp... 2 0 ... {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.842, &#39;pos&#39;: 0.158, &#39;comp... 3 0 ... {&#39;neg&#39;: 0.321, &#39;neu&#39;: 0.5, &#39;pos&#39;: 0.179, &#39;comp... 4 0 ... {&#39;neg&#39;: 0.138, &#39;neu&#39;: 0.862, &#39;pos&#39;: 0.0, &#39;comp... [5 rows x 7 columns] . df_sia = pd.json_normalize(df[(&#39;pos&#39;, &#39;compound&#39;, &#39;neu&#39;, &#39;neg&#39;)], max_level=0) df_sia.head() . neg neu pos compound . 0 0.117 | 0.768 | 0.114 | -0.0173 | . 1 0.291 | 0.709 | 0.000 | -0.7500 | . 2 0.000 | 0.842 | 0.158 | 0.4939 | . 3 0.321 | 0.500 | 0.179 | -0.2500 | . 4 0.138 | 0.862 | 0.000 | -0.4939 | . df_sia.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1600000 entries, 0 to 1599999 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 neg 1600000 non-null float64 1 neu 1600000 non-null float64 2 pos 1600000 non-null float64 3 compound 1600000 non-null float64 dtypes: float64(4) memory usage: 48.8 MB . new_df = df.join(df_sia, how=&#39;left&#39;) new_df.head() . Polarity tweet_id date flag user text (pos, compound, neu, neg) neg neu pos compound . 0 0 | 1467810369 | Mon Apr 06 22:19:45 PDT 2009 | NO_QUERY | _TheSpecialOne_ | @switchfoot http://twitpic.com/2y1zl - Awww, t... | {&#39;neg&#39;: 0.117, &#39;neu&#39;: 0.768, &#39;pos&#39;: 0.114, &#39;co... | 0.117 | 0.768 | 0.114 | -0.0173 | . 1 0 | 1467810672 | Mon Apr 06 22:19:49 PDT 2009 | NO_QUERY | scotthamilton | is upset that he can&#39;t update his Facebook by ... | {&#39;neg&#39;: 0.291, &#39;neu&#39;: 0.709, &#39;pos&#39;: 0.0, &#39;comp... | 0.291 | 0.709 | 0.000 | -0.7500 | . 2 0 | 1467810917 | Mon Apr 06 22:19:53 PDT 2009 | NO_QUERY | mattycus | @Kenichan I dived many times for the ball. Man... | {&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.842, &#39;pos&#39;: 0.158, &#39;comp... | 0.000 | 0.842 | 0.158 | 0.4939 | . 3 0 | 1467811184 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | ElleCTF | my whole body feels itchy and like its on fire | {&#39;neg&#39;: 0.321, &#39;neu&#39;: 0.5, &#39;pos&#39;: 0.179, &#39;comp... | 0.321 | 0.500 | 0.179 | -0.2500 | . 4 0 | 1467811193 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | Karoli | @nationwideclass no, it&#39;s not behaving at all.... | {&#39;neg&#39;: 0.138, &#39;neu&#39;: 0.862, &#39;pos&#39;: 0.0, &#39;comp... | 0.138 | 0.862 | 0.000 | -0.4939 | . new_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1600000 entries, 0 to 1599999 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 Polarity 1600000 non-null int64 1 tweet_id 1600000 non-null int64 2 date 1600000 non-null object 3 flag 1600000 non-null object 4 user 1600000 non-null object 5 text 1600000 non-null object 6 (pos, compound, neu, neg) 1600000 non-null object 7 neg 1600000 non-null float64 8 neu 1600000 non-null float64 9 pos 1600000 non-null float64 10 compound 1600000 non-null float64 dtypes: float64(4), int64(2), object(5) memory usage: 134.3+ MB . new_df.drop(columns=(&#39;pos&#39;, &#39;compound&#39;, &#39;neu&#39;, &#39;neg&#39;), inplace=True) # drop the dictionary column . new_df.columns # check to see dictionary dropped . Index([&#39;Polarity&#39;, &#39;tweet_id&#39;, &#39;date&#39;, &#39;flag&#39;, &#39;user&#39;, &#39;text&#39;, &#39;neg&#39;, &#39;neu&#39;, &#39;pos&#39;, &#39;compound&#39;], dtype=&#39;object&#39;) . import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline sns.displot(x=new_df[&#39;compound&#39;]) plt.show() . Create new column for Sentiment Type . conditions = [ (new_df[&#39;compound&#39;] &gt; 0.05), (new_df[&#39;compound&#39;] &gt; -0.05) &amp; (new_df[&#39;compound&#39;] &lt;= 0.05), (new_df[&#39;compound&#39;] &lt;= -0.05) ] ## create list of values to assign to the conditions values = [&#39;positive&#39;, &#39;neutral&#39;, &#39;negative&#39;] ## create a new column new_df[&#39;Sentiment&#39;] = np.select(conditions, values) new_df.head() . Polarity tweet_id date flag user text neg neu pos compound Sentiment . 0 0 | 1467810369 | Mon Apr 06 22:19:45 PDT 2009 | NO_QUERY | _TheSpecialOne_ | @switchfoot http://twitpic.com/2y1zl - Awww, t... | 0.117 | 0.768 | 0.114 | -0.0173 | neutral | . 1 0 | 1467810672 | Mon Apr 06 22:19:49 PDT 2009 | NO_QUERY | scotthamilton | is upset that he can&#39;t update his Facebook by ... | 0.291 | 0.709 | 0.000 | -0.7500 | negative | . 2 0 | 1467810917 | Mon Apr 06 22:19:53 PDT 2009 | NO_QUERY | mattycus | @Kenichan I dived many times for the ball. Man... | 0.000 | 0.842 | 0.158 | 0.4939 | positive | . 3 0 | 1467811184 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | ElleCTF | my whole body feels itchy and like its on fire | 0.321 | 0.500 | 0.179 | -0.2500 | negative | . 4 0 | 1467811193 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | Karoli | @nationwideclass no, it&#39;s not behaving at all.... | 0.138 | 0.862 | 0.000 | -0.4939 | negative | . values1 = [4, 2, 0] new_df[&#39;Polarity_new&#39;] = np.select(conditions, values1) new_df.head() . Polarity tweet_id date flag user text neg neu pos compound Sentiment Polarity_new . 0 0 | 1467810369 | Mon Apr 06 22:19:45 PDT 2009 | NO_QUERY | _TheSpecialOne_ | @switchfoot http://twitpic.com/2y1zl - Awww, t... | 0.117 | 0.768 | 0.114 | -0.0173 | neutral | 2 | . 1 0 | 1467810672 | Mon Apr 06 22:19:49 PDT 2009 | NO_QUERY | scotthamilton | is upset that he can&#39;t update his Facebook by ... | 0.291 | 0.709 | 0.000 | -0.7500 | negative | 0 | . 2 0 | 1467810917 | Mon Apr 06 22:19:53 PDT 2009 | NO_QUERY | mattycus | @Kenichan I dived many times for the ball. Man... | 0.000 | 0.842 | 0.158 | 0.4939 | positive | 4 | . 3 0 | 1467811184 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | ElleCTF | my whole body feels itchy and like its on fire | 0.321 | 0.500 | 0.179 | -0.2500 | negative | 0 | . 4 0 | 1467811193 | Mon Apr 06 22:19:57 PDT 2009 | NO_QUERY | Karoli | @nationwideclass no, it&#39;s not behaving at all.... | 0.138 | 0.862 | 0.000 | -0.4939 | negative | 0 | . import seaborn as sns %matplotlib inline sns.displot(new_df[&#39;Polarity_new&#39;]) plt.show() . sns.displot(new_df[&#39;Polarity&#39;]) plt.show() . df_neg_neu = new_df[(new_df[&#39;Polarity&#39;] == 0) &amp; (new_df[&#39;Polarity_new&#39;] == 4)] print(df_neg_neu[&#39;text&#39;].head(20)) . 2 @Kenichan I dived many times for the ball. Man... 6 Need a hug 7 @LOLTrish hey long time no see! Yes.. Rains a... 14 @smarrison i would&#39;ve been the first, but i di... 15 @iamjazzyfizzle I wish I got to watch it with ... 18 @LettyA ahh ive always wanted to see rent lov... 19 @FakerPattyPattz Oh dear. Were you drinking ou... 21 one of my friend called me, and asked to meet ... 23 this week is not going as i had hoped 28 ooooh.... LOL that leslie.... and ok I won&#39;t ... 33 @julieebaby awe i love you too!!!! 1 am here ... 38 @fleurylis I don&#39;t either. Its depressing. I d... 41 He&#39;s the reason for the teardrops on my guitar... 43 @JonathanRKnight Awww I soo wish I was there t... 44 Falling asleep. Just heard about that Tracy gi... 45 @Viennah Yay! I&#39;m happy for you with your job!... 46 Just checked my user timeline on my blackberry... 47 Oh man...was ironing @jeancjumbe&#39;s fave top to... 51 @localtweeps Wow, tons of replies from you, ma... 54 I need a hug Name: text, dtype: object . Create a Word Cloud using the Positive Words . from wordcloud import WordCloud wc = WordCloud(max_words = 2000, background_color=&#39;yellow&#39;, width = 1600, height = 1600).generate(&#39;&#39;.join(new_df[new_df.Polarity_new == 4].text)) plt.figure(figsize = (16,16), facecolor=None) plt.imshow(wc, interpolation=&#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . Create a Word Cloud using the Neutral words . from wordcloud import WordCloud wc = WordCloud(max_words = 2000, background_color=&#39;white&#39;, width = 1600, height = 1600).generate(&#39;&#39;.join(new_df[new_df.Polarity_new == 2].text)) plt.figure(figsize = (16,16), facecolor=None) plt.imshow(wc, interpolation=&#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . Create a Word Cloud using the Negative Words . from wordcloud import WordCloud wc = WordCloud(max_words = 2000, width = 1600, height = 1600).generate(&#39;&#39;.join(new_df[new_df.Polarity_new == 0].text)) plt.figure(figsize = (16,16), facecolor=None) plt.imshow(wc, interpolation=&#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . References . vaderSentiment Python Library accessed 18-October-2020. | Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014. | Kaggle Sentiment Analysis Dataset accessed 18-October-2020. | Pandas Profiling accessed 20-October-2020. |",
            "url": "https://ijeomaodoko.github.io/my-blog/python/nlp/vadersentiment/wordcloud/2020/11/02/Sentiment_Analysis.html",
            "relUrl": "/python/nlp/vadersentiment/wordcloud/2020/11/02/Sentiment_Analysis.html",
            "date": " • Nov 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Price Charts with Technical Indicators",
            "content": ". Image credits to Markus Spiske - Unsplash photos . About . There are a couple of libraries to use to calculate technical indicators for stocks. In previous posts, we had tried out the following python libraries: . mplfinance . TA-lib . In this post we will be looking at the finta library. . Install required dependencies on Google Colab . !pip install finta . Requirement already satisfied: finta in /usr/local/lib/python3.6/dist-packages (1.2) Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from finta) (1.18.5) Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from finta) (1.1.2) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;finta) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;finta) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;finta) (1.15.0) . Load required libraries . from pandas_datareader import data import numpy as np from datetime import datetime from datetime import date, timedelta import pandas as pd # import ipwidgets library and functions from __future__ import print_function from ipywidgets import interact, interactive, fixed import ipywidgets as widgets from IPython.display import display from finta import TA . Create widgets and dataframe for the stock data . Instructions for use. . Insert tuple of stock list. | Select stock from dropdown. | Select number of calendar days for dates from the last trading day. | Rerun all code after. | #tickers = (&#39;MMM&#39;, &#39;AOS&#39;, &#39;AAN&#39;, &#39;ABB&#39;, &#39;ABT&#39;, &#39;ABBV&#39;, &#39;ABM&#39;, &#39;ACN&#39;, &#39;AYI&#39;, &#39;GOLF&#39;, &#39;ADCT&#39;, &#39;ADT&#39;, &#39;AAP&#39;, &#39;ADSW&#39;, &#39;WMS&#39;, &#39;ACM&#39;, &#39;AEG&#39;, &#39;AER&#39;, &#39;AJRD&#39;, &#39;AMG&#39;, &#39;AFL&#39;, &#39;AGCO&#39;, &#39;A&#39;, &#39;AEM&#39;, &#39;ADC&#39;, &#39;AL&#39;, &#39;APD&#39;, &#39;AGI&#39;, &#39;ALK&#39;, &#39;ALB&#39;, &#39;ACI&#39;, &#39;AA&#39;, &#39;ALC&#39;, &#39;ARE&#39;, &#39;AQN&#39;, &#39;BABA&#39;, &#39;Y&#39;) #tickers = (&#39;ARKF&#39;, &#39;ARKG&#39;, &#39;ARKK&#39;, &#39;ARKW&#39;, &#39;QQQ&#39;,&#39;TQQQ&#39;, &#39;VCR&#39;, &quot;KARS&quot;, &#39;ZNGA&#39;) tickers = (&#39;SOXX&#39;, &#39;SOXL&#39;, &#39;TQQQ&#39;, &#39;QQQ&#39;, &#39;ARKK&#39;, &#39;ARKW&#39;, &#39;FDN&#39;, &#39;XLY&#39;, &#39;VCR&#39;, &#39;FPX&#39;, &#39;SMH&#39;) . stock_ticker = widgets.Dropdown( options= tickers, description=&#39;Select Stock Ticker&#39;, disabled=False, style = {&#39;description_width&#39;: &#39;initial&#39;}, layout = {&#39;width&#39;: &#39;200px&#39;} ) # create selection slider for days w = widgets.IntSlider( value=90, min=5, max=365, step=1, description = &#39;Calendar days&#39;, disabled=False, continuous_update=False, orientation=&#39;horizontal&#39;, readout=True, readout_format=&#39;d&#39;, style = {&#39;description_width&#39;: &#39;initial&#39;,&#39;handle_color&#39; : &#39;blue&#39;}, layout = {&#39;width&#39;: &#39;400px&#39;} ) # create function for time frame of selected calendar days from today def timeframe(w): days = timedelta(w) start = date.today() - days today = date.today() print(&#39;Start Date: &#39;,start, &#39; &#39; ,&#39;Last Date: &#39;,today) dates = widgets.interactive_output(timeframe, {&#39;w&#39;: w} ) display(stock_ticker, w, dates) . Download data for the stock . v = widgets.Text( value=stock_ticker.value, description=&#39;Stockticker:&#39;, disabled=True ) # create function to load stock data from yahoo def load_stock_data(stock_ticker, w): start = date.today() - timedelta(w) today = date.today() stock_data = data.DataReader(stock_ticker, start=start, end=today, data_source=&#39;yahoo&#39;) return stock_data # create dataframe for selected stock stock = load_stock_data(stock_ticker.value, w.value) # display ticker and dataframe display(v, stock) . High Low Open Close Volume Adj Close . Date . 2020-07-27 285.809998 | 280.359985 | 280.559998 | 285.690002 | 774800.0 | 284.660675 | . 2020-07-28 283.970001 | 279.609985 | 283.600006 | 280.170013 | 607500.0 | 279.160553 | . 2020-07-29 287.109985 | 282.359985 | 282.660004 | 285.940002 | 484000.0 | 284.909760 | . 2020-07-30 291.839996 | 285.040009 | 285.109985 | 291.570007 | 905800.0 | 290.519501 | . 2020-07-31 292.440002 | 285.959991 | 292.299988 | 290.390015 | 642800.0 | 289.343750 | . ... ... | ... | ... | ... | ... | ... | . 2020-10-19 330.290009 | 322.799988 | 328.350006 | 324.040009 | 402900.0 | 324.040009 | . 2020-10-20 326.380005 | 322.750000 | 325.500000 | 323.510010 | 349600.0 | 323.510010 | . 2020-10-21 324.929993 | 321.079987 | 324.279999 | 321.339996 | 358100.0 | 321.339996 | . 2020-10-22 323.140015 | 317.570007 | 321.739990 | 321.470001 | 301700.0 | 321.470001 | . 2020-10-23 320.342285 | 317.309998 | 320.239990 | 320.339996 | 243559.0 | 320.339996 | . 64 rows × 6 columns . ohlcv = stock[[&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Volume&#39;]] # select the columns in the order required ohlcv.columns = [&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;] # rename the columns ohlcv . open high low close volume . Date . 2020-07-27 280.559998 | 285.809998 | 280.359985 | 285.690002 | 774800.0 | . 2020-07-28 283.600006 | 283.970001 | 279.609985 | 280.170013 | 607500.0 | . 2020-07-29 282.660004 | 287.109985 | 282.359985 | 285.940002 | 484000.0 | . 2020-07-30 285.109985 | 291.839996 | 285.040009 | 291.570007 | 905800.0 | . 2020-07-31 292.299988 | 292.440002 | 285.959991 | 290.390015 | 642800.0 | . ... ... | ... | ... | ... | ... | . 2020-10-19 328.350006 | 330.290009 | 322.799988 | 324.040009 | 402900.0 | . 2020-10-20 325.500000 | 326.380005 | 322.750000 | 323.510010 | 349600.0 | . 2020-10-21 324.279999 | 324.929993 | 321.079987 | 321.339996 | 358100.0 | . 2020-10-22 321.739990 | 323.140015 | 317.570007 | 321.470001 | 301700.0 | . 2020-10-23 320.239990 | 320.342285 | 317.309998 | 320.339996 | 243559.0 | . 64 rows × 5 columns . Calculate some Stock Price Indicators . ex_df = ohlcv.copy() ex_df[&#39;RSI&#39;] = TA.RSI(ex_df) ex_df[&#39;Simple_Moving_Average_50&#39;] = TA.SMA(ex_df, 50) ex_df[[&#39;macd&#39;, &#39;macd_s&#39;]] = TA.MACD(ex_df) ex_df . open high low close volume RSI Simple_Moving_Average_50 macd macd_s . Date . 2020-07-27 280.559998 | 285.809998 | 280.359985 | 285.690002 | 774800.0 | NaN | NaN | 0.000000 | 0.000000 | . 2020-07-28 283.600006 | 283.970001 | 279.609985 | 280.170013 | 607500.0 | 0.000000 | NaN | -0.123846 | -0.068803 | . 2020-07-29 282.660004 | 287.109985 | 282.359985 | 285.940002 | 484000.0 | 52.956604 | NaN | 0.021123 | -0.031948 | . 2020-07-30 285.109985 | 291.839996 | 285.040009 | 291.570007 | 905800.0 | 69.775506 | NaN | 0.289809 | 0.077048 | . 2020-07-31 292.299988 | 292.440002 | 285.959991 | 290.390015 | 642800.0 | 64.565317 | NaN | 0.382753 | 0.167988 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-10-19 328.350006 | 330.290009 | 322.799988 | 324.040009 | 402900.0 | 61.934468 | 305.0528 | 7.295558 | 5.988757 | . 2020-10-20 325.500000 | 326.380005 | 322.750000 | 323.510010 | 349600.0 | 61.243647 | 305.5992 | 6.966201 | 6.184246 | . 2020-10-21 324.279999 | 324.929993 | 321.079987 | 321.339996 | 358100.0 | 58.372764 | 306.1640 | 6.456954 | 6.238787 | . 2020-10-22 321.739990 | 323.140015 | 317.570007 | 321.470001 | 301700.0 | 58.498281 | 306.5420 | 5.994638 | 6.189958 | . 2020-10-23 320.239990 | 320.342285 | 317.309998 | 320.339996 | 243559.0 | 56.892503 | 306.9576 | 5.474535 | 6.046873 | . 64 rows × 9 columns . Create a function to create a dataframe that captures some stock technical indicators . def create_dataframe(df): &quot;&quot;&quot; This function creates a Dataframe for key indicators &quot;&quot;&quot; df[&#39;Daily_Returns&#39;] = df[&#39;close&#39;].pct_change() # create column for daily returns df[&#39;Price_Up_or_Down&#39;] = np.where(df[&#39;Daily_Returns&#39;] &lt; 0, -1, 1) # create column for price up or down # add columns for the volatility and volume indicators df[&#39;Average_True_Range&#39;] = TA.ATR(df) df[&#39;On_Balance_Volume&#39;] = TA.OBV(df) df[&#39;Volume_Flow_Indicator&#39;] = TA.VFI(df) ## add column for moving averages df[&#39;Simple_Moving_Average_50&#39;] = TA.SMA(df, 50) #df[&#39;Simple_Moving_Average_200&#39;] = TA.SMA(df, 200) df[&#39;Volume Weighted Average Price&#39;] = TA.VWAP(df) df[&#39;Exponential_Moving_Average_50&#39;] = TA.EMA(df, 50) # add columns for momentum indicators df[&#39;ADX&#39;] = TA.ADX(df) #create column for ADX assume timeperiod of 14 days df[&#39;RSI&#39;] = TA.RSI(df) #create column for RSI assume timeperiod of 14 days df[&#39;William %R&#39;] = TA.WILLIAMS(df) #create column for William %R use high, low and close, and assume timeperiod of 14 days df[&#39;MFI&#39;] = TA.MFI(df) #create column for MFI use high, low and close, and assume timeperiod of 14 days df[&#39;MOM&#39;] = TA.MOM(df) df[[&#39;macd&#39;, &#39;macd_signal&#39;]] = TA.MACD(df) return df # return the dataframe . stocks_df = create_dataframe(df = ohlcv) stocks_df . open high low close volume Daily_Returns Price_Up_or_Down Average_True_Range On_Balance_Volume Volume_Flow_Indicator Simple_Moving_Average_50 Volume Weighted Average Price Exponential_Moving_Average_50 ADX RSI William %R MFI MOM macd macd_signal . Date . 2020-07-27 280.559998 | 285.809998 | 280.359985 | 285.690002 | 774800.0 | NaN | 1 | NaN | NaN | NaN | NaN | 283.953328 | 285.690002 | NaN | NaN | NaN | NaN | NaN | 0.000000 | 0.000000 | . 2020-07-28 283.600006 | 283.970001 | 279.609985 | 280.170013 | 607500.0 | -0.019322 | -1 | NaN | -607500.0 | NaN | NaN | 282.765256 | 282.874808 | NaN | 0.000000 | NaN | NaN | NaN | -0.123846 | -0.068803 | . 2020-07-29 282.660004 | 287.109985 | 282.359985 | 285.940002 | 484000.0 | 0.020595 | 1 | NaN | -123500.0 | NaN | NaN | 283.380248 | 283.937676 | NaN | 52.956604 | NaN | NaN | NaN | 0.021123 | -0.031948 | . 2020-07-30 285.109985 | 291.839996 | 285.040009 | 291.570007 | 905800.0 | 0.019689 | 1 | NaN | 782300.0 | NaN | NaN | 285.374468 | 285.961739 | NaN | 69.775506 | NaN | NaN | NaN | 0.289809 | 0.077048 | . 2020-07-31 292.299988 | 292.440002 | 285.959991 | 290.390015 | 642800.0 | -0.004047 | -1 | NaN | 139500.0 | NaN | NaN | 286.169230 | 286.919634 | NaN | 64.565317 | NaN | NaN | NaN | 0.382753 | 0.167988 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-10-19 328.350006 | 330.290009 | 322.799988 | 324.040009 | 402900.0 | -0.005036 | -1 | 6.673575 | -2998700.0 | NaN | 305.0528 | 302.215983 | 308.643875 | 21.807370 | 61.934468 | -26.619171 | 73.111215 | 12.809998 | 7.295558 | 5.988757 | . 2020-10-20 325.500000 | 326.380005 | 322.750000 | 323.510010 | 349600.0 | -0.001636 | -1 | 6.591433 | -3348300.0 | NaN | 305.5992 | 302.441020 | 309.282507 | 21.538161 | 61.243647 | -28.335488 | 67.203975 | 13.760010 | 6.966201 | 6.184246 | . 2020-10-21 324.279999 | 324.929993 | 321.079987 | 321.339996 | 358100.0 | -0.006708 | -1 | 6.358575 | -3706400.0 | NaN | 306.1640 | 302.648519 | 309.798550 | 20.885840 | 58.372764 | -35.362732 | 60.498775 | 5.660004 | 6.456954 | 6.238787 | . 2020-10-22 321.739990 | 323.140015 | 317.570007 | 321.470001 | 301700.0 | 0.000405 | 1 | 6.060004 | -3404700.0 | NaN | 306.5420 | 302.805099 | 310.296289 | 19.461344 | 58.498281 | -38.371303 | 63.592417 | 1.880005 | 5.994638 | 6.189958 | . 2020-10-23 320.239990 | 320.342285 | 317.309998 | 320.339996 | 243559.0 | -0.003515 | -1 | 5.663574 | -3648259.0 | NaN | 306.9576 | 302.919847 | 310.723146 | 18.081831 | 56.892503 | -50.126215 | 58.242238 | -4.869995 | 5.474535 | 6.046873 | . 64 rows × 20 columns . VISUALIZATIONS USING PLOTLY . Price Action Chart . import plotly.graph_objects as go fig_ohlc = go.Figure(data=[go.Ohlc(x=stocks_df.index, open=stocks_df[&#39;open&#39;], high=stocks_df[&#39;high&#39;], low=stocks_df[&#39;low&#39;], close=stocks_df[&#39;close&#39;], showlegend=False)]) fig_ohlc.update_layout(title = &#39;Price Action Chart&#39;, yaxis_title = &#39;Stock Price&#39;, template = &#39;presentation&#39;) fig_ohlc.update(layout_xaxis_rangeslider_visible=False) display(v) fig_ohlc.show() . . . import plotly.graph_objects as go fig_candle = go.Figure(data=[go.Candlestick(x=stocks_df.index, open=stocks_df[&#39;open&#39;], high=stocks_df[&#39;high&#39;], low=stocks_df[&#39;low&#39;], close=stocks_df[&#39;close&#39;], showlegend=False)]) fig_candle.update_layout(title = &#39;Price Action Chart&#39;, yaxis_title = &#39;Stock Price&#39;, template = &#39;presentation&#39;) fig_candle.update(layout_xaxis_rangeslider_visible=False) display(v) fig_candle.show() . . . Momentum Indicators . import plotly.graph_objects as go trace1 = go.Scatter(x=stocks_df.index, y=stocks_df[&#39;macd&#39;], mode=&#39;lines&#39;, marker=dict(color=&quot;green&quot;), showlegend=True, name=&#39;macd&#39;) trace2 = go.Scatter(x=stocks_df.index, y=stocks_df[&#39;macd_signal&#39;], mode=&#39;lines&#39;, marker=dict(color=&quot;blue&quot;), showlegend=True, name=&#39;macd_signal&#39;) data= [trace1, trace2] layout = go.Layout(title = &#39;MACD indicator&#39;) fig = go.Figure(data=data, layout=layout) fig.show() . . . References . Plotly Figure Reference accessed October 22, 2020. . FinTA (Financial Technical Analysis) python library accessed October 22, 2020. .",
            "url": "https://ijeomaodoko.github.io/my-blog/stocks/python/finta/pandas/plotly/ipywidgets/2020/10/23/Stock_Price_Indicators_using_the_python_FINTA_library.html",
            "relUrl": "/stocks/python/finta/pandas/plotly/ipywidgets/2020/10/23/Stock_Price_Indicators_using_the_python_FINTA_library.html",
            "date": " • Oct 23, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Scrape and Summarize News Articles using Python",
            "content": "About . This project will scrape and summarize news articles using nltk and newspaper3K python libraries. . We will try to download a summary of all the articles based on the news headlines for a particular ticker symbol in this case &#39;NDX&#39; (the NASDAQ-100 index) from the Nasdaq website. . To go to the url for a specific ticker simply replace the ticker value with your ticker of choice. . http://www.nasdaq.com/symbol/**ndx**/news-headlines . Install Required Libraries . !pip install nltk !pip install newspaper3k . Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0) Collecting newspaper3k Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB) |████████████████████████████████| 215kB 6.5MB/s Collecting tinysegmenter==0.3 Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz Requirement already satisfied: nltk&gt;=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5) Collecting tldextract&gt;=2.0.1 Downloading https://files.pythonhosted.org/packages/5d/c3/f4e90ae5b7dd02257c3b9dfb6747aba0b8a9c788f5401700fda055e814fc/tldextract-3.0.1-py2.py3-none-any.whl (86kB) |████████████████████████████████| 92kB 5.2MB/s Collecting feedfinder2&gt;=0.0.4 Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz Requirement already satisfied: PyYAML&gt;=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13) Requirement already satisfied: requests&gt;=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0) Requirement already satisfied: Pillow&gt;=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0) Collecting jieba3k&gt;=0.35.1 Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB) |████████████████████████████████| 7.4MB 7.1MB/s Collecting feedparser&gt;=5.2.1 Downloading https://files.pythonhosted.org/packages/2c/84/df6de99cba01afc82344c9cb3a79df100a00ac33396120f8aa66c72f0d84/feedparser-6.0.1-py2.py3-none-any.whl (80kB) |████████████████████████████████| 81kB 10.7MB/s Collecting cssselect&gt;=0.9.2 Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl Requirement already satisfied: lxml&gt;=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6) Requirement already satisfied: python-dateutil&gt;=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1) Requirement already satisfied: beautifulsoup4&gt;=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk&gt;=3.2.1-&gt;newspaper3k) (1.15.0) Requirement already satisfied: filelock&gt;=3.0.8 in /usr/local/lib/python3.6/dist-packages (from tldextract&gt;=2.0.1-&gt;newspaper3k) (3.0.12) Collecting requests-file&gt;=1.4 Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract&gt;=2.0.1-&gt;newspaper3k) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (2020.6.20) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.10.0-&gt;newspaper3k) (1.24.3) Collecting sgmllib3k Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k Building wheel for tinysegmenter (setup.py) ... done Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13538 sha256=21d80e684d759950290a5522214b146594a5846d32b0ca24500b2fddca70553e Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02 Building wheel for feedfinder2 (setup.py) ... done Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3355 sha256=f080f14c61ae68c7a747068c93d0abf2acb08950d0cae3dc16a21a1857a781d1 Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed Building wheel for jieba3k (setup.py) ... done Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=a36c59aa31ede8f68ac300bf99f8eed3d23c555646fcd8d810de80648a540526 Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34 Building wheel for sgmllib3k (setup.py) ... done Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp36-none-any.whl size=6067 sha256=65eb0a2526fecb90fd3c1fb03c6fb531514631316c5b46f960ac526206787c77 Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k Installing collected packages: tinysegmenter, requests-file, tldextract, feedfinder2, jieba3k, sgmllib3k, feedparser, cssselect, newspaper3k Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.0.1 . import nltk import newspaper import datetime import pandas as pd . Load the newspaper articles . ndx_news = newspaper.build(&#39;https://www.nasdaq.com/market-activity/index/ndx/news-headlines&#39;) for article in ndx_news.articles: print(article.url) . http://ir.nasdaq.com/Income-Statement-Trend-Summary-and-GAAP-to-Non-GAAP-Reconciliation http://ir.nasdaq.com/events/event-details/barclays-global-financial-services-conference-2020 http://ir.nasdaq.com/events/event-details/ubs-virtual-financial-services-conference-2020 https://www.nasdaq.com/videos/tradetalks%3A-what-trends-will-dominate-the-next-decade https://www.nasdaq.com/videos/can-stock-picking-ever-be-fun-again https://www.nasdaq.com/videos/tradetalks%3A-how-will-2020-impact-investment-portfolios https://www.nasdaq.com/videos/tradetalks%3A-the-toys-for-tots-campaign-for-holiday-2020 https://www.nasdaq.com/videos/tradetalks%3A-the-launch-of-jaaa-and-democratizing-access-to-clos https://www.nasdaq.com/videos/tradetalks%3A-what-paypals-cryptocurrency-means-for-growth-in-the-space https://www.nasdaq.com/videos/tradetalks%3A-how-do-franchise-businesses-properly-open-while-protecting-staff-and-customers https://www.nasdaq.com/videos/tradetalks%3A-volatility-around-elections-is-normal https://www.nasdaq.com/videos/tradetalks%3A-finding-the-best-credit-card-for-you-credit-best-practices-and-rewards-trends https://www.nasdaq.com/videos/investing-strategies%3A-crowdstrike-ceo-insights-how-to-handle-election-2020-market-volatility https://www.nasdaq.com/videos/investing-strategies%3A-long-term-investing%3A-tips-to-maximize-returns-as-you-set-and-forget https://www.nasdaq.com/videos/investing-strategies%3A-election-2020%3A-how-to-handle-your-portfolio-amid-market-moving https://www.nasdaq.com/videos/investing-strategies%3A-crowdstrike-ceo-on-security-software-leadership-work-from-anywhere https://www.nasdaq.com/videos/investing-strategies%3A-one-on-one-with-cadence-ceo-a-look-at-blank-check-ipos-analysis-of https://www.nasdaq.com/videos/investing-strategies%3A-top-stocks-to-watch%3A-cadence-ceo-on-track-record-of-innovation-growth https://www.nasdaq.com/videos/investing-strategies%3A-virgin-galactic-draftkings-nikola-whats-next-everything-you-need-to https://www.nasdaq.com/videos/investing-strategies%3A-analyzing-strength-of-large-cap-tech-stocks-in-current-bull-market https://www.nasdaq.com/videos/investing-strategies%3A-health-care-trends-to-watch-with-medical-sector-on-the-move https://www.nasdaq.com/videos/investing-strategies%3A-trader-education%3A-ibds-top-investing-rules-for-beginners https://www.nasdaq.com/videos/how-clean-is-the-fashion-industry https://www.nasdaq.com/videos/whiskey-as-a-covid-19-hedge https://www.nasdaq.com/videos/a-cyclical-move-overall-in-the-markets-is-afoot-bofas-hyzy-says https://www.nasdaq.com/videos/ignoring-science-led-to-over-200000-u.s.-deaths%3A-johns-hopkins https://www.nasdaq.com/videos/markets-undergoing-a-reality-check%3A-fidelitys-richards https://www.nasdaq.com/videos/its-getting-tougher-for-opec-to-cut-oil-output%3A-nomura https://www.nasdaq.com/news-and-insights/in-the-money-with-fidelity-investments-dan-nathan https://www.nasdaq.com/articles/iphone-12-could-be-a-tailwind-for-apples-accessories-segment-says-analyst-2020-10-23 https://www.nasdaq.com/articles/covid-19-is-driving-a-surge-in-e-commerce-ad-spending-2020-10-23 https://www.nasdaq.com/articles/the-pandemic-shopping-list%3A-dolls-detergent-and-campers-2020-10-23 https://www.nasdaq.com/articles/the-advantages-of-blockchain-over-traditional-payments-2020-10-23 https://www.nasdaq.com/articles/forget-5g%3A-this-tech-stock-trend-is-generating-even-bigger-returns-2020-10-23 https://www.nasdaq.com/articles/whats-happening-with-moderna-stock-2020-10-19 https://www.nasdaq.com/articles/3-top-5g-stocks-to-buy-right-now-2020-10-09 https://www.nasdaq.com/articles/3-high-yield-stocks-at-rock-bottom-prices-2020-10-16 https://www.nasdaq.com/articles/workhorse-stock-could-skyrocket-on-a-u.s.-postal-service-contract-2020-10-16 https://www.nasdaq.com/articles/intel-intc-3rd-quarter-earnings%3A-what-to-expect-2020-10-22 https://www.nasdaq.com/articles/microsoft-msft-1st-quarter-earnings%3A-what-to-expect-2020-10-21 https://www.nasdaq.com/articles/tesla-tsla-3rd-quarter-earnings%3A-what-to-expect-2020-10-21 https://www.nasdaq.com/articles/netflix-nflx-3rd-quarter-earnings%3A-what-to-expect-2020-10-20 https://www.nasdaq.com/articles/is-the-market-reaction-to-intels-intc-earnings-overdone-2020-10-23 https://www.nasdaq.com/articles/the-market-is-focused-on-stimulus-will-it-come-soon-or-at-all-2020-10-22 https://www.nasdaq.com/articles/the-reaction-to-netflixs-nflx-earnings%3A-deja-vu-all-over-again-2020-10-21 https://www.nasdaq.com/articles/u.s.-debt%3A-the-elephant-in-the-room-that-keeps-growing-2020-10-19 https://www.nasdaq.com/articles/daily-markets%3A-stocks-could-hinge-on-news-from-washington-on-stimulus-or-lack-thereof-2020 https://www.nasdaq.com/articles/wall-st-week-ahead-more-u.s.-companies-offer-earnings-guidance-despite-pandemic-2020-10-23 https://www.nasdaq.com/articles/why-investors-should-be-upbeat-about-exxon-mobil-2020-10-21 https://www.nasdaq.com/articles/top-stock-trades-for-thursday%3A-snap-fb-pins-pypl-2020-10-21 https://www.nasdaq.com/articles/plug-workhorse-stock-into-your-trading-portfolio-because-it-is-electric-2020-10-21 https://www.nasdaq.com/articles/how-good-is-the-surf-in-ocean-power-technologies-stock-2020-10-21 https://www.nasdaq.com/articles/bp-bp-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/target-tgt-outpaces-stock-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/united-parcel-service-ups-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/hanesbrands-hbi-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/dominion-energy-d-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/noble-midstream-partners-nblx-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/ciena-cien-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/enbridge-enb-stock-sinks-as-market-gains%3A-what-you-should-know-2020-10-23 https://www.nasdaq.com/articles/nasdaqs-johan-toll-wins-fintech-person-year-2018-05-16 https://www.nasdaq.com/articles/adena-friedman%3A-esg-ai-cryptocurrency-in-focus-at-davos-2019-01-21 https://www.nasdaq.com/article/invesco-qqq-celebrates-20-years-of-curating-innovation-cm1112647?utm_source=Nasdaq_LINKEDIN_COMPANY_2185074219&amp;utm_medium=QQQ%20anniversary%20__%20%C2%A0 https://www.nasdaq.com/solutions/midpoint-extended-life-order-m-elo . for category in ndx_news.category_urls(): print(category) . https://www.nasdaq.com/market-activity/index/ndx/news-headlines https://www.nasdaq.com/mediakit https://www.nasdaq.com/GlobalIndexes https://www.nasdaq.com/TotalMarkets https://www.nasdaq.com/marketsite http://ir.nasdaq.com https://www.nasdaq.com/public-policy https://www.nasdaq.com/videos https://www.nasdaq.com https://www.nasdaq.com/symbol https://www.nasdaq.com/solutions https://portfolio.nasdaq.com https://www.nasdaq.com/trust-center https://www.nasdaq.com/ESG-Guide . ndx_article = ndx_news.articles[0] ndx_article.download() ndx_article.parse() nltk.download(&#39;punkt&#39;) ndx_article.nlp() . [nltk_data] Downloading package punkt to /root/nltk_data... [nltk_data] Unzipping tokenizers/punkt.zip. . ndx_article.summary . &#39;&#39; . ndx_article.keywords . [&#39;nongaap&#39;, &#39;trend&#39;, &#39;income&#39;, &#39;gaap&#39;, &#39;summary&#39;, &#39;reconciliation&#39;, &#39;statement&#39;] . ndx_article.publish_date . ndx_article.authors . [] . ndx_article.title . &#39;Income Statement Trend Summary and GAAP to Non-GAAP Reconciliation&#39; . Create Dataframe for the articles . url = [] keywords = [] title = [] published =[] summary = [] authors=[] videos = [] for article in ndx_news.articles: url.append(article.url) article.download() article.parse() article.nlp() keywords.append(article.keywords) title.append(article.title) published.append(article.publish_date) summary.append(article.summary) authors.append(article.authors) videos.append(article.movies) . type(url) . list . len(url) . 64 . data = [url, title, published, authors, summary, keywords, videos] # create list of lists df = pd.DataFrame(data).transpose() #transpose to get 7 columns instead of 62 df.columns=[&#39;url&#39;, &#39;title&#39;, &#39;published&#39;, &#39;authors&#39;, &#39;summary&#39;, &#39;keywords&#39;, &#39;videos&#39;] # name the columns df . url title published authors summary keywords videos . 0 http://ir.nasdaq.com/Income-Statement-Trend-Su... | Income Statement Trend Summary and GAAP to Non... | NaT | [] | | [nongaap, trend, income, gaap, summary, reconc... | [] | . 1 http://ir.nasdaq.com/events/event-details/barc... | Barclays Global Financial Services Conference ... | NaT | [] | | [financial, services, barclays, 2020, global, ... | [] | . 2 http://ir.nasdaq.com/events/event-details/ubs-... | UBS Virtual Financial Services Conference 2020 | NaT | [] | | [financial, services, ubs, virtual, 2020, conf... | [] | . 3 https://www.nasdaq.com/videos/tradetalks%3A-wh... | #TradeTalks: What Trends Will Dominate the Nex... | NaT | [] | Caleb Silver from Investopedia returns to #Tra... | [investopedia, silver, decade, tradetalks, ret... | [] | . 4 https://www.nasdaq.com/videos/can-stock-pickin... | Can Stock Picking Ever be Fun Again? | NaT | [] | Michael Holland, Holland &amp; Co. founder, talks ... | [picking, surveillance, strategy, stock, bloom... | [] | . ... ... | ... | ... | ... | ... | ... | ... | . 59 https://www.nasdaq.com/articles/enbridge-enb-s... | Enbridge (ENB) Stock Sinks As Market Gains: Wh... | 2020-10-23 | [Zacks Equity Research] | In the latest trading session, Enbridge (ENB) ... | [sinks, enbridge, ratio, enb, stock, estimate,... | [] | . 60 https://www.nasdaq.com/articles/nasdaqs-johan-... | Nasdaq&#39;s Johan Toll Wins FinTech Person of the... | 2018-05-16 | [] | Johan Toll, head of Blockchain Product Managem... | [markets, johan, financial, nasdaq, toll, trad... | [] | . 61 https://www.nasdaq.com/articles/adena-friedman... | Adena Friedman: ESG, AI, Cryptocurrency In Foc... | 2019-01-21 | [] | The world economy is growing more slowly than ... | [focus, markets, public, economic, nasdaq, com... | [] | . 62 https://www.nasdaq.com/article/invesco-qqq-cel... | Invesco QQQ Celebrates 20 Years of Curating In... | NaT | [] | Invesco recognizes leading ETF’s long-standing... | [funds, dec, growth, 20, invesco, 2018, rank, ... | [] | . 63 https://www.nasdaq.com/solutions/midpoint-exte... | Midpoint Extended Life Order (M-ELO) | NaT | [] | See M-ELO in action and learn moreNasdaq&#39;s EVP... | [public, extended, structure, life, services, ... | [] | . 64 rows × 7 columns . Inspect the data . print(df.loc[0,&#39;summary&#39;]) . . for i in df.columns: print(df.loc[3, i]) . https://www.nasdaq.com/videos/tradetalks%3A-what-trends-will-dominate-the-next-decade #TradeTalks: What Trends Will Dominate the Next Decade? NaT [] Caleb Silver from Investopedia returns to #TradeTalks! He and Jill Malandrino go over what trends will dominate in the next decade. [&#39;investopedia&#39;, &#39;silver&#39;, &#39;decade&#39;, &#39;tradetalks&#39;, &#39;returns&#39;, &#39;dominate&#39;, &#39;trends&#39;, &#39;malandrino&#39;, &#39;jill&#39;, &#39;caleb&#39;] [] . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 64 entries, 0 to 63 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 url 64 non-null object 1 title 64 non-null object 2 published 32 non-null datetime64[ns] 3 authors 64 non-null object 4 summary 64 non-null object 5 keywords 64 non-null object 6 videos 64 non-null object dtypes: datetime64[ns](1), object(6) memory usage: 3.6+ KB . df[&#39;published&#39;].unique() . array([ &#39;NaT&#39;, &#39;2020-10-23T00:00:00.000000000&#39;, &#39;2020-10-19T00:00:00.000000000&#39;, &#39;2020-10-09T00:00:00.000000000&#39;, &#39;2020-10-16T00:00:00.000000000&#39;, &#39;2020-10-22T00:00:00.000000000&#39;, &#39;2020-10-21T00:00:00.000000000&#39;, &#39;2020-10-20T00:00:00.000000000&#39;, &#39;2018-05-16T00:00:00.000000000&#39;, &#39;2019-01-21T00:00:00.000000000&#39;], dtype=&#39;datetime64[ns]&#39;) . df_null = df[df[&#39;published&#39;].isnull()] df_null[&#39;url&#39;] . 0 http://ir.nasdaq.com/Income-Statement-Trend-Su... 1 http://ir.nasdaq.com/events/event-details/barc... 2 http://ir.nasdaq.com/events/event-details/ubs-... 3 https://www.nasdaq.com/videos/tradetalks%3A-wh... 4 https://www.nasdaq.com/videos/can-stock-pickin... 5 https://www.nasdaq.com/videos/tradetalks%3A-ho... 6 https://www.nasdaq.com/videos/tradetalks%3A-th... 7 https://www.nasdaq.com/videos/tradetalks%3A-th... 8 https://www.nasdaq.com/videos/tradetalks%3A-wh... 9 https://www.nasdaq.com/videos/tradetalks%3A-ho... 10 https://www.nasdaq.com/videos/tradetalks%3A-vo... 11 https://www.nasdaq.com/videos/tradetalks%3A-fi... 12 https://www.nasdaq.com/videos/investing-strate... 13 https://www.nasdaq.com/videos/investing-strate... 14 https://www.nasdaq.com/videos/investing-strate... 15 https://www.nasdaq.com/videos/investing-strate... 16 https://www.nasdaq.com/videos/investing-strate... 17 https://www.nasdaq.com/videos/investing-strate... 18 https://www.nasdaq.com/videos/investing-strate... 19 https://www.nasdaq.com/videos/investing-strate... 20 https://www.nasdaq.com/videos/investing-strate... 21 https://www.nasdaq.com/videos/investing-strate... 22 https://www.nasdaq.com/videos/how-clean-is-the... 23 https://www.nasdaq.com/videos/whiskey-as-a-cov... 24 https://www.nasdaq.com/videos/a-cyclical-move-... 25 https://www.nasdaq.com/videos/ignoring-science... 26 https://www.nasdaq.com/videos/markets-undergoi... 27 https://www.nasdaq.com/videos/its-getting-toug... 28 https://www.nasdaq.com/news-and-insights/in-th... 46 https://www.nasdaq.com/articles/daily-markets%... 62 https://www.nasdaq.com/article/invesco-qqq-cel... 63 https://www.nasdaq.com/solutions/midpoint-exte... Name: url, dtype: object . Download Dataframe to a CSV file . df_dates = df.dropna(subset=[&#39;published&#39;]).sort_values(by=[&#39;published&#39;], inplace=False, ascending=False) #drop rows that did not load the published dates, and sort by date published df_dates . url title published authors summary keywords videos . 29 https://www.nasdaq.com/articles/iphone-12-coul... | iPhone 12 Could Be a Tailwind for Apple’s Acce... | 2020-10-23 | [Marty Shtrubel] | Apple’s (AAPL) accessories business might make... | [aapl, tailwind, 12, opinions, feature, access... | [] | . 56 https://www.nasdaq.com/articles/dominion-energ... | Dominion Energy (D) Stock Sinks As Market Gain... | 2020-10-23 | [Zacks Equity Research] | Dominion Energy (D) closed at $81.14 in the la... | [sinks, energy, d, stock, ratio, gains, estima... | [] | . 53 https://www.nasdaq.com/articles/target-tgt-out... | Target (TGT) Outpaces Stock Market Gains: What... | 2020-10-23 | [Zacks Equity Research] | On that day, TGT is projected to report earnin... | [tgt, ratio, stock, estimate, gains, stocks, s... | [] | . 52 https://www.nasdaq.com/articles/bp-bp-stock-si... | BP (BP) Stock Sinks As Market Gains: What You ... | 2020-10-23 | [Zacks Equity Research] | In the latest trading session, BP (BP) closed ... | [sinks, reflect, revisions, stock, estimate, g... | [] | . 47 https://www.nasdaq.com/articles/wall-st-week-a... | Wall St Week Ahead-More U.S. companies offer e... | 2020-10-23 | [David Randall] | By David RandallNEW YORK, Oct 23 (Reuters) - W... | [sp, investors, far, week, offer, pandemic, re... | [] | . 30 https://www.nasdaq.com/articles/covid-19-is-dr... | COVID-19 Is Driving a Surge in E-Commerce Ad S... | 2020-10-23 | [Evan Niu] | That&#39;s also causing a related surge in ad spen... | [covid19, surge, fool, ad, revenue, ecommerce,... | [] | . 42 https://www.nasdaq.com/articles/is-the-market-... | Is the Market Reaction to Intel&#39;s (INTC) Earni... | 2020-10-23 | [] | It is not unusual for a stock to fall followin... | [stock, good, growth, revenue, intc, billion, ... | [] | . 55 https://www.nasdaq.com/articles/hanesbrands-hb... | HanesBrands (HBI) Stock Sinks As Market Gains:... | 2020-10-23 | [Zacks Equity Research] | In the latest trading session, HanesBrands (HB... | [sinks, trading, hbi, stock, stocks, gains, ra... | [] | . 54 https://www.nasdaq.com/articles/united-parcel-... | United Parcel Service (UPS) Stock Sinks As Mar... | 2020-10-23 | [Zacks Equity Research] | United Parcel Service (UPS) closed at $171.90 ... | [sinks, service, transportation, ratio, gained... | [] | . 57 https://www.nasdaq.com/articles/noble-midstrea... | Noble Midstream Partners (NBLX) Stock Sinks As... | 2020-10-23 | [Zacks Equity Research] | Noble Midstream Partners (NBLX) closed at $9.0... | [sinks, trading, revisions, stock, estimate, g... | [] | . 58 https://www.nasdaq.com/articles/ciena-cien-sto... | Ciena (CIEN) Stock Sinks As Market Gains: What... | 2020-10-23 | [Zacks Equity Research] | Our research shows that these estimate changes... | [sinks, ciena, ratio, stock, estimate, gains, ... | [] | . 59 https://www.nasdaq.com/articles/enbridge-enb-s... | Enbridge (ENB) Stock Sinks As Market Gains: Wh... | 2020-10-23 | [Zacks Equity Research] | In the latest trading session, Enbridge (ENB) ... | [sinks, enbridge, ratio, enb, stock, estimate,... | [] | . 33 https://www.nasdaq.com/articles/forget-5g%3A-t... | Forget 5G: This Tech Stock Trend Is Generating... | 2020-10-23 | [Leo Sun] | A wide range of industries will benefit from t... | [snowflake, silobusting, stock, trend, forget,... | [] | . 32 https://www.nasdaq.com/articles/the-advantages... | The Advantages of Blockchain over Traditional ... | 2020-10-23 | [] | By eliminating middlemen, cross-border blockch... | [funds, stack, transaction, trust, payments, b... | [] | . 31 https://www.nasdaq.com/articles/the-pandemic-s... | The pandemic shopping list: Dolls, detergent a... | 2020-10-23 | [Uday Sampath] | Oct 23 (Reuters) - Consumers have been snappin... | [quarterly, views, list, dolls, robot, revenue... | [] | . 38 https://www.nasdaq.com/articles/intel-intc-3rd... | Intel (INTC) 3rd Quarter Earnings: What to Expect | 2020-10-22 | [] | Chip stocks have caught fire, thanks to strong... | [3rd, company, billion, revenue, intc, strong,... | [] | . 43 https://www.nasdaq.com/articles/the-market-is-... | The Market Is Focused on Stimulus; Will It Com... | 2020-10-22 | [] | For a few weeks now, the stock market seems to... | [stimulus, weeks, democrats, thing, focused, c... | [] | . 39 https://www.nasdaq.com/articles/microsoft-msft... | Microsoft (MSFT) 1st Quarter Earnings: What to... | 2020-10-21 | [] | The software giant is set to report first quar... | [microsofts, cloud, 1st, azure, billion, growt... | [] | . 40 https://www.nasdaq.com/articles/tesla-tsla-3rd... | Tesla (TSLA) 3rd Quarter Earnings: What to Expect | 2020-10-21 | [] | Tesla&#39;s strong stock surge has been driven by ... | [3rd, vehicles, company, vehicle, totals, reve... | [] | . 44 https://www.nasdaq.com/articles/the-reaction-t... | The Reaction to Netflix&#39;s (NFLX) Earnings: Déj... | 2020-10-21 | [] | Netflix (NFLX) released earnings after the bel... | [released, political, nflx, growth, revenue, t... | [] | . 48 https://www.nasdaq.com/articles/why-investors-... | Why Investors Should Be Upbeat About Exxon Mobil | 2020-10-21 | [Chris Tyler] | InvestorPlace - Stock Market News, Stock Advic... | [shares, investors, stock, oil, exxon, income,... | [] | . 49 https://www.nasdaq.com/articles/top-stock-trad... | Top Stock Trades for Thursday: SNAP, FB, PINS,... | 2020-10-21 | [Bret Kenwell] | InvestorPlace - Stock Market News, Stock Advic... | [trades, shares, trading, pypl, stock, pins, t... | [] | . 50 https://www.nasdaq.com/articles/plug-workhorse... | Plug Workhorse Stock into Your Trading Portfol... | 2020-10-21 | [Nicolas Chahine] | InvestorPlace - Stock Market News, Stock Advic... | [workhorse, trading, twice, stock, stocks, tra... | [] | . 51 https://www.nasdaq.com/articles/how-good-is-th... | How Good Is the Surf in Ocean Power Technologi... | 2020-10-21 | [Chris Tyler] | Some are seeing dollar signs in Ocean Power Te... | [purchase, energy, stock, technologies, good, ... | [] | . 41 https://www.nasdaq.com/articles/netflix-nflx-3... | Netflix (NFLX) 3rd Quarter Earnings: What to E... | 2020-10-20 | [] | Netflix (NFLX) is set to report third quarter ... | [3rd, netflix, company, stock, nflx, billion, ... | [] | . 45 https://www.nasdaq.com/articles/u.s.-debt%3A-t... | U.S. Debt: The Elephant in the Room That Keeps... | 2020-10-19 | [] | The elephant referred to back then was the nat... | [trillion, yes, room, gdp, debt, elephant, don... | [] | . 34 https://www.nasdaq.com/articles/whats-happenin... | What&#39;s Happening With Moderna Stock? | 2020-10-19 | [Trefis Team] | To recall, earlier this month, Moderna agreed ... | [covid19, doses, vaccine, stock, phase, likely... | [] | . 37 https://www.nasdaq.com/articles/workhorse-stoc... | Workhorse Stock Could Skyrocket on a U.S. Post... | 2020-10-16 | [Tom Taulli] | InvestorPlace - Stock Market News, Stock Advic... | [service, workhorse, vehicles, company, stock,... | [] | . 36 https://www.nasdaq.com/articles/3-high-yield-s... | 3 High-Yield Stocks at Rock-Bottom Prices | 2020-10-16 | [James Brumley] | It&#39;s easy to be wary of dividend stocks right ... | [att, lyondellbasell, stock, stocks, interest,... | [] | . 35 https://www.nasdaq.com/articles/3-top-5g-stock... | 3 Top 5G Stocks to Buy Right Now | 2020-10-09 | [Leo Sun] | AppleApple is widely expected to reveal the iP... | [apple, skyworks, stock, stocks, earnings, 5g,... | [] | . 61 https://www.nasdaq.com/articles/adena-friedman... | Adena Friedman: ESG, AI, Cryptocurrency In Foc... | 2019-01-21 | [] | The world economy is growing more slowly than ... | [focus, markets, public, economic, nasdaq, com... | [] | . 60 https://www.nasdaq.com/articles/nasdaqs-johan-... | Nasdaq&#39;s Johan Toll Wins FinTech Person of the... | 2018-05-16 | [] | Johan Toll, head of Blockchain Product Managem... | [markets, johan, financial, nasdaq, toll, trad... | [] | . from google.colab import files df_dates.to_csv(&#39;NDX_news_headlines_accessed_2020-10-23.csv&#39;, index=False) files.download(&#39;NDX_news_headlines_accessed_2020-10-23.csv&#39;) . References: . NDX News Headlines accessed 23-October-2020. | Quickstart Guide - Newspaper accessed 18-October-2020. | Scraping articles about stocks accessed 18-October-2020. | Scrape and Summarize News Articles by Computer Science accessed 18-October-2020. |",
            "url": "https://ijeomaodoko.github.io/my-blog/python/nlp/scrape_website/2020/10/18/Scrape_and_Summarize_News_Articles_about_Stocks.html",
            "relUrl": "/python/nlp/scrape_website/2020/10/18/Scrape_and_Summarize_News_Articles_about_Stocks.html",
            "date": " • Oct 18, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Stock Price Charts With Power Bi",
            "content": "Create Stock Price Indicator Dashboard in Power BI . toc:true- branch: master- badges: true- comments: true | author: Ijeoma Odoko | categories: [python, power bi, jupyter] | . About . The purpose of this project is to create a dataframe capturing stock price data and calculating indicator values using Python, and then visualize it in Power BI in a simple dashboard. . Key steps taken include: . Create the virtual environment for Windows in Anaconda. | Download the required libraries, and the stock price and volume data from yahoo finance using the pandas_datareader python API into a pandas dataframe. | Calculate the stock indicator values using the TA-lib Python library. Use the Pandas Library if function not available in TA-lib. | Convert the dataframe(s) to csv files to use in Power BI. | Create dashboard with the indicator values in Power BI. | Step 1: Create the Virtual Environment for Windows in Anaconda . Create a new python 3.7 environment in Anaconda. Reference this cheatsheet. . Download the TA-Lib wrapper from here. To choose the right one you need to know the python version in your environment, and computer’s operating system (32bit or 64bit). . Move it to the same Computer path that shows on your Anaconda Powershell prompt for your new virtual environment. . Run pip install with the TA-Lib file name, see picture below. . Pip Install all other required libraries like pandas, datetime, pandas_datareader. . . Step 2: Download required python libraries and data from Yahoo Finance . # import python libraries from pandas_datareader import data import numpy as np from datetime import datetime from datetime import date, timedelta import pandas as pd import talib . # Create Parameters Number_of_days = input(&#39;Enter Calendar days:&#39;) print(Number_of_days) Stock_Ticker = input(&#39;Enter Stock Ticker:&#39;) print(Stock_Ticker) Moving_Average = input(&#39;Enter Bollinger Bands Moving Average Type (Simple or Exponential): &#39;) if Moving_Average == &#39;Simple&#39;: print(Moving_Average) elif Moving_Average == &#39;Exponential&#39;: print(Moving_Average) else: print(&#39;error&#39;) Days = int(Number_of_days) . Enter Calendar days:740 740 Enter Stock Ticker:TQQQ TQQQ Enter Bollinger Bands Moving Average Type (Simple or Exponential): Simple Simple . # load stock data from yahoo start = date.today() - timedelta(Days) today = date.today() df = data.DataReader(Stock_Ticker, start=start, end=today, data_source=&#39;yahoo&#39;) . Step 3: Create stock indicator values using Pandas and TA-lib library . # ADD INDICATORS TO MAIN DATAFRAME df df[&#39;Daily_Returns&#39;] = df[&#39;Adj Close&#39;].pct_change() # create column for daily returns df[&#39;Price_Up_or_Down&#39;] = np.where(df[&#39;Daily_Returns&#39;] &lt; 0, -1, 1) # create column for price up or down ## add columns for the volatility and volume indicators from talib import ATR, OBV, ADX, RSI df[&#39;Average_True_Range&#39;] = ATR(df[&#39;High&#39;], df[&#39;Low&#39;], df[&#39;Close&#39;]) df[&#39;On_Balance_Volume&#39;] = OBV(df[&#39;Adj Close&#39;], df[&#39;Volume&#39;]) ## add columns for momentum indicators from talib import ADX, RSI, STOCH, WILLR, MFI df[&#39;ADX&#39;] = ADX(df[&#39;High&#39;], df[&#39;Low&#39;], df[&#39;Close&#39;], timeperiod=14) #create column for ADX assume timeperiod of 14 days df[&#39;RSI&#39;] = RSI(df[&#39;Adj Close&#39;],timeperiod=14) #create column for RSI assume timeperiod of 14 days df[&#39;William_%R&#39;] = WILLR(df[&#39;High&#39;],df[&#39;Low&#39;], df[&#39;Close&#39;], timeperiod=14) #create column for William %R use high, low and close, and assume timeperiod of 14 days df[&#39;MFI&#39;] = MFI(df[&#39;High&#39;],df[&#39;Low&#39;], df[&#39;Close&#39;], df[&#39;Volume&#39;], timeperiod=14) #create column for MFI use high, low and close, and assume timeperiod of 14 days ## add columns for statistic functions from talib import LINEARREG, TSF adj_close = df[&#39;Adj Close&#39;].to_numpy() # create ndarray from the adj_close prices df[&#39;Linear_Regression&#39;] = LINEARREG(adj_close, timeperiod=14) df[&#39;Time_Series_Forecast&#39;] = TSF(adj_close, timeperiod=14) ## add column for moving averages from talib import MA, SMA, EMA, WMA #import the moving average functions df[&#39;Simple_Moving_Average_50&#39;] = SMA(df[&#39;Adj Close&#39;], timeperiod=50) df[&#39;Simple_Moving_Average_200&#39;] = SMA(df[&#39;Adj Close&#39;], timeperiod=200) ## add columns for momentum indicators STOCH_df slowk, slowd = STOCH(df[&#39;High&#39;], df[&#39;Low&#39;], df[&#39;Close&#39;], fastk_period= 5, slowk_period= 3, slowk_matype= 0, slowd_period = 3, slowd_matype = 0) # uses high, low, close by default STOCH_array = np.array([slowk, slowd]).transpose() STOCH_df = pd.DataFrame(data = STOCH_array, index=df.index, columns=[&#39;STOCH_slowk&#39;, &#39;STOCH_slowd&#39;]) df = STOCH_df[[&#39;STOCH_slowk&#39;, &#39;STOCH_slowd&#39;]].join(df, how=&#39;right&#39;) # join STOCH to main dataframe # CREATE Bollinger Bands® DATAFRAME WITH Bollinger Bands® INDICATORS from talib import BBANDS ## Parameters BBands_periods = 20 SDnumber = 2 if Moving_Average == &#39;Simple&#39;: moving_avg= 0 else: moving_avg = 1 upperband, middleband, lowerband = BBANDS(adj_close, timeperiod=BBands_periods, nbdevup=SDnumber, nbdevdn = SDnumber, matype=moving_avg) # calculate the bollinger bands assuming the middle band as the simple moving average bands = np.array([upperband, middleband, lowerband]).transpose() # transpose the ndarrays stocks_bollingerbands = pd.DataFrame(data = bands, index = df.index, columns=[&#39;BB_upperband&#39;, &#39;BB_middleband&#39;, &#39;BB_lowerband&#39;]) # create dataframe from the ndarrays stocks_bollingerbands = df[[&#39;Adj Close&#39;]].join(stocks_bollingerbands, how=&#39;left&#39;) # add Adj Close Column and volume to bollinger bands dataframe stocks_bollingerbands[&#39;BB_Width&#39;] = (stocks_bollingerbands[&#39;BB_upperband&#39;] - stocks_bollingerbands[&#39;BB_lowerband&#39;]).div(stocks_bollingerbands[&#39;BB_middleband&#39;]) # add column for Bollinger Band Width stocks_bollingerbands[&#39;Percent_B&#39;] = (stocks_bollingerbands[&#39;Adj Close&#39;] - stocks_bollingerbands[&#39;BB_lowerband&#39;]).div(stocks_bollingerbands[&#39;BB_upperband&#39;] - stocks_bollingerbands[&#39;BB_lowerband&#39;]).mul(100) # add column for Percent B ## create list for Bollinger Bands® buy/sell strategy conditions buy_or_sell = [ (stocks_bollingerbands[&#39;Adj Close&#39;] &gt; stocks_bollingerbands[&#39;BB_upperband&#39;]), (stocks_bollingerbands[&#39;Adj Close&#39;] &lt; stocks_bollingerbands[&#39;BB_lowerband&#39;]) ] choices = [&#39;Sell&#39;, &#39;Buy&#39;] stocks_bollingerbands[&#39;Action&#39;] = np.select(buy_or_sell, choices, default = &#39;Neutral&#39;) # create new column for action to take based on BollingerBand values stocks_bollingerbands.drop(columns=&#39;Adj Close&#39;, inplace=True) # drop Adj Close column stocks_bollingerbands.dropna(inplace=True) # drop empty rows # CREATE MERGED DATAFRAME # join Bollinger Bands® dataframe to main dataframe to create new stocks_df = stocks_bollingerbands.join(df, how=&#39;left&#39;) stocks_df . BB_upperband BB_middleband BB_lowerband BB_Width Percent_B Action STOCH_slowk STOCH_slowd High Low ... Average_True_Range On_Balance_Volume ADX RSI William_%R MFI Linear_Regression Time_Series_Forecast Simple_Moving_Average_50 Simple_Moving_Average_200 . Date . 2018-10-30 70.023204 | 57.441679 | 44.860155 | 0.438063 | 15.693175 | Neutral | 27.900666 | 27.639096 | 49.049999 | 45.570000 | ... | 5.123637 | -1.397404e+08 | NaN | 31.158793 | -71.739130 | 32.891829 | 49.628769 | 48.881414 | NaN | NaN | . 2018-10-31 67.553510 | 56.486655 | 45.419801 | 0.391840 | 30.191152 | Neutral | 46.609921 | 35.213573 | 53.660000 | 51.250000 | ... | 5.096948 | -1.172207e+08 | NaN | 36.433929 | -53.344484 | 41.639084 | 48.860358 | 48.009042 | NaN | NaN | . 2018-11-01 65.799976 | 55.848475 | 45.896975 | 0.356375 | 42.609367 | Neutral | 71.598957 | 48.703181 | 54.619999 | 51.439999 | ... | 4.960023 | -1.014624e+08 | NaN | 39.862677 | -40.635438 | 40.177119 | 49.358470 | 48.622607 | NaN | NaN | . 2018-11-02 64.439876 | 55.214786 | 45.989696 | 0.334153 | 32.264480 | Neutral | 83.134317 | 67.114398 | 54.930000 | 50.799999 | ... | 4.900736 | -1.232571e+08 | NaN | 37.529625 | -54.236345 | 40.113450 | 49.019171 | 48.272671 | NaN | NaN | . 2018-11-05 63.153036 | 54.613530 | 46.074023 | 0.312725 | 31.381121 | Neutral | 78.868933 | 77.867402 | 52.139999 | 49.759998 | ... | 4.720684 | -1.360822e+08 | NaN | 37.041639 | -57.079145 | 34.302688 | 49.342788 | 48.745978 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-10-06 138.348875 | 125.399501 | 112.450128 | 0.206530 | 54.172024 | Neutral | 31.246967 | 50.686292 | 135.119995 | 125.150002 | ... | 9.713780 | 1.352882e+09 | 20.178407 | 48.428622 | -38.672007 | 42.728684 | 132.350001 | 133.575605 | 131.548601 | 95.623291 | . 2020-10-07 138.518796 | 125.452501 | 112.386207 | 0.208307 | 79.379039 | Neutral | 49.199414 | 46.141732 | 134.110001 | 129.380005 | ... | 9.564938 | 1.381018e+09 | 19.732322 | 52.268168 | -16.483153 | 49.831451 | 134.138573 | 135.507804 | 132.055401 | 95.863445 | . 2020-10-08 139.695310 | 125.985501 | 112.275692 | 0.217641 | 83.204312 | Neutral | 55.772146 | 45.406176 | 136.610001 | 133.539993 | ... | 9.130299 | 1.405755e+09 | 18.965605 | 53.370095 | -9.943310 | 57.363264 | 135.420572 | 136.782528 | 132.528001 | 96.110250 | . 2020-10-09 141.996039 | 126.955001 | 111.913964 | 0.236951 | 97.021374 | Neutral | 83.294339 | 62.755300 | 141.389999 | 136.960007 | ... | 8.928135 | 1.430164e+09 | 17.616138 | 56.673091 | -0.900041 | 64.342049 | 137.913431 | 139.403519 | 133.084601 | 96.386550 | . 2020-10-12 147.458290 | 128.269001 | 109.079712 | 0.299204 | 117.722658 | Sell | 90.841647 | 76.636044 | 158.729996 | 146.860001 | ... | 9.549696 | 1.466805e+09 | 18.085055 | 62.874384 | -9.019373 | 64.782233 | 144.046286 | 146.150660 | 133.782201 | 96.717500 | . 491 rows × 26 columns . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; DatetimeIndex: 510 entries, 2018-10-03 to 2020-10-12 Data columns (total 20 columns): # Column Non-Null Count Dtype -- -- 0 STOCH_slowk 502 non-null float64 1 STOCH_slowd 502 non-null float64 2 High 510 non-null float64 3 Low 510 non-null float64 4 Open 510 non-null float64 5 Close 510 non-null float64 6 Volume 510 non-null float64 7 Adj Close 510 non-null float64 8 Daily_Returns 509 non-null float64 9 Price_Up_or_Down 510 non-null int32 10 Average_True_Range 496 non-null float64 11 On_Balance_Volume 510 non-null float64 12 ADX 483 non-null float64 13 RSI 496 non-null float64 14 William_%R 497 non-null float64 15 MFI 496 non-null float64 16 Linear_Regression 497 non-null float64 17 Time_Series_Forecast 497 non-null float64 18 Simple_Moving_Average_50 461 non-null float64 19 Simple_Moving_Average_200 311 non-null float64 dtypes: float64(19), int32(1) memory usage: 101.7 KB . stocks_bollingerbands.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; DatetimeIndex: 491 entries, 2018-10-30 to 2020-10-12 Data columns (total 6 columns): # Column Non-Null Count Dtype -- -- 0 BB_upperband 491 non-null float64 1 BB_middleband 491 non-null float64 2 BB_lowerband 491 non-null float64 3 BB_Width 491 non-null float64 4 Percent_B 491 non-null float64 5 Action 491 non-null object dtypes: float64(5), object(1) memory usage: 46.9+ KB . stocks_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; DatetimeIndex: 491 entries, 2018-10-30 to 2020-10-12 Data columns (total 26 columns): # Column Non-Null Count Dtype -- -- 0 BB_upperband 491 non-null float64 1 BB_middleband 491 non-null float64 2 BB_lowerband 491 non-null float64 3 BB_Width 491 non-null float64 4 Percent_B 491 non-null float64 5 Action 491 non-null object 6 STOCH_slowk 491 non-null float64 7 STOCH_slowd 491 non-null float64 8 High 491 non-null float64 9 Low 491 non-null float64 10 Open 491 non-null float64 11 Close 491 non-null float64 12 Volume 491 non-null float64 13 Adj Close 491 non-null float64 14 Daily_Returns 491 non-null float64 15 Price_Up_or_Down 491 non-null int32 16 Average_True_Range 491 non-null float64 17 On_Balance_Volume 491 non-null float64 18 ADX 483 non-null float64 19 RSI 491 non-null float64 20 William_%R 491 non-null float64 21 MFI 491 non-null float64 22 Linear_Regression 491 non-null float64 23 Time_Series_Forecast 491 non-null float64 24 Simple_Moving_Average_50 461 non-null float64 25 Simple_Moving_Average_200 311 non-null float64 dtypes: float64(24), int32(1), object(1) memory usage: 121.7+ KB . Step 4: Download dataframes to csv . Power BI only supports the following python packages: source . matplotlib . numpy . pandas . scikit-learn . scipy . seaborn . statsmodels . ## send to CSV file df.to_csv(r&quot;C: TQQQ_df.csv&quot;, sep = &#39;,&#39;) stocks_bollingerbands.to_csv(r&quot;C: TQQQ_bbands.csv&quot;, sep=&#39;,&#39;) . Step 5: Create visual dashboard in Power BI using the dataframes . . References . Fidelity, Percent B (% B). Accessed October 1, 2020. . Fidelity, Bollinger Band® Width. Accessed October 1, 2020. . Fidelity, Bollinger Bands®. Accessed October 1, 2020. . TA-lib python library. Accessed October 1, 2020. . Williams %R. Accessed October 9, 2020 . Money Flow IndexAccessed October 9, 2020. . Relative Strength IndexAccessed October 9, 2020. . ADX: The Trend Strength IndicatorAccessed October 9, 2020. . Bollinger Bands Rules. Accessed October 1, 2020. . .",
            "url": "https://ijeomaodoko.github.io/my-blog/2020/10/12/Stock-Price-Charts-with-Power-BI.html",
            "relUrl": "/2020/10/12/Stock-Price-Charts-with-Power-BI.html",
            "date": " • Oct 12, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Stock Price Movement Charts using Python",
            "content": "This purpose of this project was to create stock price movement charts with widgets for interactivity using the available python libraries. . Price Movement Charts . Price movement charts help with timing the market for buying or selling opportunities by determining up and down trends in price movement. These charts can typically be used with any financial time series like stocks, bonds, options, futures or commodities. . Renko . Is a type of price movement chart that has no time dimension. The key parameter it requires is the box size which signifies each brick (price movement size). The box size can be set to a specific value, or it be set to be equal to the ATR (average true range) which is derived from the closing price of the stock. With these charts its able to quickly tell the direction of trend changes. . PNF . PNF otherwise known as Point and Figure Chart is very similar to the renko chart, in that it also does not have a time dimension. An X represents when the price has moved higher, and an O represents when the price has dropped. The PNF also has a box size that can be set as a specific value, or be equal to the ATR (average true range). . OHLC . This is a type of price movement chart that captures the open, high, low and closing prices for each given trading day. . The vertical line represents the range in prices from high to low for the day. The horizontal lines extending out from the vertical line, represents open price for the left, and close price for the right. . Candlestick . Also known as Japanese candlesticks are a type of price movement chart that takes into consideration both price, time and volume. It helps to determine the sentiment of the market - Bullish or Bearish. Bullish - would indicate a buy, while Bearish - would indicate short or sell for a stock trader. . Candlestick patterns can help determine price direction and momentum. One key thing to note when using candlesticks to understand price movement, it is important to first identify the market trend, before finding candlestick patterns in the data. Candlestick patterns are also best suited for identifying short term price movements. . Long and short days . Long days refers to large price movement within the trading day, and short days refers to low price movement within the trading day. This comparison however is best suited for short-term price movement of about 5-10days. . Load required libraries . Pandas_datareader to import historical data on stocks from yahoo. | Pandas for working with large data sets. | Datetime for handling date datatypes. | Matplotlib for data visualization. | ipwidgets for interactive widgets | Numpy for handling numeric arrays. | mplfinance for creating price movement charts | . !pip install mplfinance . Requirement already satisfied: mplfinance in /usr/local/lib/python3.6/dist-packages (0.12.7a0) Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mplfinance) (1.1.2) Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mplfinance) (3.2.2) Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;mplfinance) (1.18.5) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;mplfinance) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;mplfinance) (2018.9) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;mplfinance) (2.4.7) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;mplfinance) (0.10.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;mplfinance) (1.2.0) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;mplfinance) (1.15.0) . from pandas_datareader import data import numpy as np from datetime import datetime from datetime import date, timedelta import pandas as pd import matplotlib.pyplot as plt %matplotlib inline # import ipwidgets library and functions from __future__ import print_function from ipywidgets import interact, interactive, fixed import ipywidgets as widgets from IPython.display import display import mplfinance as mpf mpf.__version__ . &#39;0.12.7a0&#39; . Create widgets and dataframe for the stock data . Instructions for use. . Insert tuple of stock list. | Select stock from dropdown. | Select number of calendar days for dates from the last trading day. | Rerun all code after. | Create widget for stock list and number of calendar days . options = (&#39;MMM&#39;, &#39;AOS&#39;, &#39;AAN&#39;, &#39;ABB&#39;, &#39;ABT&#39;, &#39;ABBV&#39;, &#39;ABM&#39;, &#39;ACN&#39;, &#39;AYI&#39;, &#39;GOLF&#39;, &#39;ADCT&#39;, &#39;ADT&#39;, &#39;AAP&#39;, &#39;ADSW&#39;, &#39;WMS&#39;, &#39;ACM&#39;, &#39;AEG&#39;, &#39;AER&#39;, &#39;AJRD&#39;, &#39;AMG&#39;, &#39;AFL&#39;, &#39;AGCO&#39;, &#39;A&#39;, &#39;AEM&#39;, &#39;ADC&#39;, &#39;AL&#39;, &#39;APD&#39;, &#39;AGI&#39;, &#39;ALK&#39;, &#39;ALB&#39;, &#39;ACI&#39;, &#39;AA&#39;, &#39;ALC&#39;, &#39;ARE&#39;, &#39;AQN&#39;, &#39;BABA&#39;, &#39;Y&#39;) # create dropdown for selected stocks stock_ticker = widgets.Dropdown( options= options, description=&#39;Select Stock Ticker&#39;, disabled=False, style = {&#39;description_width&#39;: &#39;initial&#39;}, layout = {&#39;width&#39;: &#39;200px&#39;} ) # create selection slider for days w = widgets.IntSlider( value=90, min=5, max=365, step=1, description = &#39;Calendar days&#39;, disabled=False, continuous_update=False, orientation=&#39;horizontal&#39;, readout=True, readout_format=&#39;d&#39;, style = {&#39;description_width&#39;: &#39;initial&#39;,&#39;handle_color&#39; : &#39;blue&#39;}, layout = {&#39;width&#39;: &#39;400px&#39;} ) # create function for time frame of selected calendar days from today def timeframe(w): days = timedelta(w) start = date.today() - days today = date.today() print(&#39;Start Date: &#39;,start, &#39; &#39; ,&#39;Last Date: &#39;,today) dates = widgets.interactive_output(timeframe, {&#39;w&#39;: w} ) display(stock_ticker, w, dates) . Download data for the stock . v = widgets.Text( value=stock_ticker.value, description=&#39;Stockticker:&#39;, disabled=True ) # create function to load stock data from yahoo def load_stock_data(stock_ticker, w): start = date.today() - timedelta(w) today = date.today() stock_data = data.DataReader(stock_ticker, start=start, end=today, data_source=&#39;yahoo&#39;) return stock_data # create dataframe for selected stock stock = load_stock_data(stock_ticker.value, w.value) # display ticker and dataframe display(v, stock) . High Low Open Close Volume Adj Close . Date . 2020-08-10 251.750000 | 246.100006 | 249.339996 | 248.130005 | 13621700 | 248.130005 | . 2020-08-11 252.880005 | 247.830002 | 251.289993 | 248.419998 | 10681800 | 248.419998 | . 2020-08-12 256.079987 | 248.679993 | 249.250000 | 255.190002 | 11120400 | 255.190002 | . 2020-08-13 256.970001 | 252.880005 | 256.390015 | 253.720001 | 8794500 | 253.720001 | . 2020-08-14 255.770004 | 251.639999 | 255.490005 | 253.970001 | 7876400 | 253.970001 | . 2020-08-17 257.375000 | 250.085007 | 253.000000 | 256.959991 | 9760000 | 256.959991 | . 2020-08-18 261.420013 | 256.059998 | 258.709991 | 259.200012 | 13267800 | 259.200012 | . 2020-08-19 261.290009 | 257.380005 | 260.890015 | 260.589996 | 14096500 | 260.589996 | . 2020-08-20 258.880005 | 254.179993 | 256.890015 | 257.970001 | 21460800 | 257.970001 | . 2020-08-21 267.429993 | 258.309998 | 259.029999 | 265.799988 | 25648200 | 265.799988 | . 2020-08-24 276.970001 | 271.619995 | 273.239990 | 276.019989 | 22475800 | 276.019989 | . 2020-08-25 289.119995 | 276.040009 | 278.059998 | 286.000000 | 27535500 | 286.000000 | . 2020-08-26 292.480011 | 284.100006 | 289.260010 | 291.959991 | 19530300 | 291.959991 | . 2020-08-27 290.250000 | 282.100006 | 290.170013 | 284.170013 | 14805800 | 284.170013 | . 2020-08-28 289.500000 | 283.570007 | 285.089996 | 289.000000 | 9689600 | 289.000000 | . 2020-08-31 289.190002 | 283.609985 | 288.619995 | 287.029999 | 13253800 | 287.029999 | . 2020-09-01 298.000000 | 288.869995 | 289.200012 | 298.000000 | 13815900 | 298.000000 | . 2020-09-02 299.000000 | 289.790009 | 299.000000 | 296.070007 | 12638600 | 296.070007 | . 2020-09-03 290.733002 | 278.160004 | 289.000000 | 282.500000 | 16766200 | 282.500000 | . 2020-09-04 283.779999 | 267.390015 | 279.600006 | 281.390015 | 15885800 | 281.390015 | . 2020-09-08 273.970001 | 266.589996 | 270.230011 | 270.019989 | 12734000 | 270.019989 | . 2020-09-09 275.640015 | 270.880005 | 274.450012 | 273.149994 | 9465700 | 273.149994 | . 2020-09-10 277.100006 | 267.399994 | 274.899994 | 267.549988 | 10676800 | 267.549988 | . 2020-09-11 274.529999 | 268.119995 | 272.630005 | 271.609985 | 9412800 | 271.609985 | . 2020-09-14 276.290009 | 271.760010 | 275.359985 | 274.100006 | 7883300 | 274.100006 | . 2020-09-15 279.100006 | 274.799988 | 278.000000 | 277.959991 | 8291400 | 277.959991 | . 2020-09-16 283.605011 | 278.000000 | 281.029999 | 278.140015 | 9583500 | 278.140015 | . 2020-09-17 275.899994 | 272.321014 | 273.109985 | 275.720001 | 8016900 | 275.720001 | . 2020-09-18 277.269989 | 270.549988 | 275.980011 | 272.410004 | 11753500 | 272.410004 | . 2020-09-21 274.220001 | 266.399994 | 269.100006 | 273.820007 | 9076400 | 273.820007 | . 2020-09-22 276.320007 | 270.049988 | 276.019989 | 275.290009 | 9673300 | 275.290009 | . 2020-09-23 277.829987 | 271.500000 | 275.399994 | 272.950012 | 7353200 | 272.950012 | . 2020-09-24 271.250000 | 267.334015 | 267.929993 | 269.730011 | 9562100 | 269.730011 | . 2020-09-25 271.809998 | 264.559998 | 267.570007 | 271.089996 | 11466600 | 271.089996 | . 2020-09-28 278.839996 | 274.199005 | 275.529999 | 276.010010 | 8761700 | 276.010010 | . 2020-09-29 279.299988 | 274.899994 | 275.429993 | 276.929993 | 7673300 | 276.929993 | . 2020-09-30 295.000000 | 283.709991 | 284.010010 | 293.980011 | 24709900 | 293.980011 | . Visualize percentage daily changes for the selected stock over time . stock_data_return = stock[&#39;Adj Close&#39;].pct_change().mul(100) stock_data_return.plot(figsize=[12,6], grid=True, title = stock_ticker.value) plt.ylabel(&quot;Adjusted Close Returns&quot;) plt.show() . Visualise the stock price data using different price movement indicators . Instruction for use. . Select Chart Type and style. | All the charts assume 10, 20 or 50 days for moving average . chart_types = [(&#39;Line Price Chart&#39;, &#39;line&#39;), (&#39;Renko Price Chart&#39;, &#39;renko&#39;), (&#39;PNF Price Chart&#39;,&#39;pnf&#39;), (&#39;Candlestick Price Chart&#39;, &#39;candle&#39;), (&#39;OHLC Price Chart&#39;, &#39;ohlc&#39;)] chart = widgets.Dropdown( options= chart_types, description=&#39;Select Chart Type&#39;, disabled=False, style = {&#39;description_width&#39;: &#39;initial&#39;}, layout = {&#39;width&#39;: &#39;300px&#39;} ) # create drop down using mplfinance library built-in styles style_options = [&#39;binance&#39;, &#39;blueskies&#39;, &#39;brasil&#39;, &#39;charles&#39;, &#39;checkers&#39;, &#39;classic&#39;, &#39;default&#39;, &#39;mike&#39;, &#39;nightclouds&#39;, &#39;sas&#39;, &#39;starsandstripes&#39;, &#39;yahoo&#39;] style_option = widgets.Dropdown( options= style_options, description=&#39;Select Style&#39;, disabled=False, style = {&#39;description_width&#39;: &#39;initial&#39;}, layout = {&#39;width&#39;: &#39;300px&#39;} ) # create plot function using mplfinance library # fixed values for moving average (mav), figratio, and figscale, volume=True # default settings for renko and pnf charts (bricksize = &#39;atr&#39;, box_size=&#39;atr&#39;) def create_plot(chart, style_option): return mpf.plot(stock, type=chart, volume=True, mav = (10,20,50), figratio=(15, 8) , figscale=1.5, style=style_option, title = &#39; n&#39;f&#39;{stock_ticker.value}&#39;) widgets.interactive(create_plot, chart=chart, style_option=style_option) . References . mplfinance Accessed September 25, 2020. . | Jupyter Widgets Accessed September 25, 2020. . | Datareader basic example (Yahoo Finance) . | Morris, Gregory L., 1948-, Candlestick charting explained timeless techniques for trading stocks and futures [electronic resource], New York : McGraw-Hill, c2006, 3rd ed. . | Price Movement ChartsAccessed September 25, 2020. . | Renko Charts Accessed September 25, 2020. . | PNF Charts Accessed September 25, 2020. . |",
            "url": "https://ijeomaodoko.github.io/my-blog/2020/09/30/Price-Movement-Charts-using-mplfinance-Python-Library.html",
            "relUrl": "/2020/09/30/Price-Movement-Charts-using-mplfinance-Python-Library.html",
            "date": " • Sep 30, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Ijeoma Odoko is a Data Savvy Engineer, who loves to manipulate data transforming it into insightful information. . I created this blog to capture my learnings in data analytics by writing articles. Join me on my journey. . My most recent data projects can be found here. . LinkedIn Profile . Github Profile .",
          "url": "https://ijeomaodoko.github.io/my-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ijeomaodoko.github.io/my-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}